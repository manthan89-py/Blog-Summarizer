{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Summarizer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80a296a9a8c4f0cabf5f7b123641102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201aad00bba046ef8a2499d3b79fdee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2be0303ab4d4ce19ce653ae050b0b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940e8d05d1d243e9b7d210493847548d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc08994485ff45a985c7424fffbb0dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://medium.com/swlh/fake-news-detection-using-machine-learning-69ff9050351f'\n",
    "URL2 = 'https://medium.com/swlh/automatic-image-captioning-using-deep-learning-5e899c127387'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html lang=\"en\"><head><script defer src=\"https://cdn.optimizely.com/js/16180790160.js\"></script><title data-rh=\"true\">Automatic Image Captioning Using Deep Learning | by Manthan Bhikadiya | The Startup | Medium</title><meta data-rh=\"true\" charset=\"utf-8\"/><meta data-rh=\"true\" name=\"viewport\" content=\"width=device-width,minimum-scale=1,initial-scale=1\"/><meta data-rh=\"true\" name=\"theme-color\" content=\"#000000\"/><meta data-rh=\"true\" name=\"twitter:app:name:iphone\" content=\"Medium\"/><meta data-rh=\"true\" name=\"twitter:app:id:iphone\" content=\"828256236\"/><meta data-rh=\"true\" property=\"al:ios:app_name\" content=\"Medium\"/><meta data-rh=\"true\" property=\"al:ios:app_store_id\" content=\"828256236\"/><meta data-rh=\"true\" property=\"al:android:package\" content=\"com.medium.reader\"/><meta data-rh=\"true\" property=\"fb:app_id\" content=\"542599432471018\"/><meta data-rh=\"true\" property=\"og:site_name\" content=\"Medium\"/><meta data-rh=\"true\" property=\"og:type\" content=\"article\"/><meta data-rh=\"true\" property=\"article:published_time\" content=\"2021-02-07T05:35:50.821Z\"/><meta data-rh=\"true\" name=\"title\" content=\"Automatic Image Captioning Using Deep Learning | by Manthan Bhikadiya | The Startup | Medium\"/><meta data-rh=\"true\" property=\"og:title\" content=\"Automatic Image Captioning Using Deep Learning\"/><meta data-rh=\"true\" property=\"twitter:title\" content=\"Automatic Image Captioning Using Deep Learning\"/><meta data-rh=\"true\" name=\"twitter:site\" content=\"@thestartup_\"/><meta data-rh=\"true\" name=\"twitter:app:url:iphone\" content=\"medium://p/5e899c127387\"/><meta data-rh=\"true\" property=\"al:android:url\" content=\"medium://p/5e899c127387\"/><meta data-rh=\"true\" property=\"al:ios:url\" content=\"medium://p/5e899c127387\"/><meta data-rh=\"true\" property=\"al:android:app_name\" content=\"Medium\"/><meta data-rh=\"true\" name=\"description\" content=\"Deep learning and Machine learning are the most progressive technologies in this era. Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans…\"/><meta data-rh=\"true\" property=\"og:description\" content=\"Overview of Deep Learning:\"/><meta data-rh=\"true\" property=\"twitter:description\" content=\"Overview of Deep Learning:\"/><meta data-rh=\"true\" property=\"og:url\" content=\"https://medium.com/swlh/automatic-image-captioning-using-deep-learning-5e899c127387\"/><meta data-rh=\"true\" property=\"al:web:url\" content=\"https://medium.com/swlh/automatic-image-captioning-using-deep-learning-5e899c127387\"/><meta data-rh=\"true\" property=\"og:image\" content=\"https://miro.medium.com/max/564/0*ENpcH_oTsR4CNlNg.png\"/><meta data-rh=\"true\" name=\"twitter:image:src\" content=\"https://miro.medium.com/max/564/0*ENpcH_oTsR4CNlNg.png\"/><meta data-rh=\"true\" name=\"twitter:card\" content=\"summary_large_image\"/><meta data-rh=\"true\" property=\"article:author\" content=\"https://medium.com/@manthan.bhikadiya\"/><meta data-rh=\"true\" name=\"author\" content=\"Manthan Bhikadiya\"/><meta data-rh=\"true\" name=\"robots\" content=\"index,follow,max-image-preview:large\"/><meta data-rh=\"true\" name=\"referrer\" content=\"unsafe-url\"/><meta data-rh=\"true\" name=\"twitter:label1\" value=\"Reading time\"/><meta data-rh=\"true\" name=\"twitter:data1\" value=\"7 min read\"/><meta data-rh=\"true\" name=\"parsely-post-id\" content=\"5e899c127387\"/><link data-rh=\"true\" rel=\"search\" type=\"application/opensearchdescription+xml\" title=\"Medium\" href=\"/osd.xml\"/><link data-rh=\"true\" rel=\"apple-touch-icon\" sizes=\"152x152\" href=\"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon\" sizes=\"120x120\" href=\"https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon\" sizes=\"76x76\" href=\"https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon\" sizes=\"60x60\" href=\"https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"/><link data-rh=\"true\" rel=\"mask-icon\" href=\"https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg\" color=\"#171717\"/><link data-rh=\"true\" id=\"glyph_preload_link\" rel=\"preload\" as=\"style\" type=\"text/css\" href=\"https://glyph.medium.com/css/unbound.css\"/><link data-rh=\"true\" id=\"glyph_link\" rel=\"stylesheet\" type=\"text/css\" href=\"https://glyph.medium.com/css/unbound.css\"/><link data-rh=\"true\" rel=\"author\" href=\"https://medium.com/@manthan.bhikadiya\"/><link data-rh=\"true\" rel=\"canonical\" href=\"https://medium.com/swlh/automatic-image-captioning-using-deep-learning-5e899c127387\"/><link data-rh=\"true\" rel=\"alternate\" href=\"android-app://com.medium.reader/https/medium.com/p/5e899c127387\"/><link data-rh=\"true\" rel=\"icon\" href=\"https://miro.medium.com/1*m-R_BkNf1Qjr1YbyOIJY2w.png\"/><script data-rh=\"true\" type=\"application/ld+json\">{\"@context\":\"http:\\\\u002F\\\\u002Fschema.org\",\"@type\":\"NewsArticle\",\"image\":[\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F1200\\\\u002F0*ENpcH_oTsR4CNlNg.png\"],\"url\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fautomatic-image-captioning-using-deep-learning-5e899c127387\",\"dateCreated\":\"2020-10-05T04:59:44.562Z\",\"datePublished\":\"2020-10-05T04:59:44.562Z\",\"dateModified\":\"2021-02-07T05:36:00.718Z\",\"headline\":\"Automatic Image Captioning Using Deep Learning - The Startup - Medium\",\"name\":\"Automatic Image Captioning Using Deep Learning - The Startup - Medium\",\"description\":\"Deep learning and Machine learning are the most progressive technologies in this era. Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans…\",\"identifier\":\"5e899c127387\",\"keywords\":[\"Lite:true\",\"Tag:Image Captioning\",\"Tag:Machine Learning\",\"Tag:Deep Learning\",\"Tag:Computer Vision\",\"Tag:Naturallanguageprocessing\",\"Publication:swlh\",\"Elevated:false\",\"LockedPostSource:LOCKED_POST_SOURCE_NONE\",\"LayerCake:3\"],\"author\":{\"@type\":\"Person\",\"name\":\"Manthan Bhikadiya\",\"url\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002F@manthan.bhikadiya\"},\"creator\":[\"Manthan Bhikadiya\"],\"publisher\":{\"@type\":\"Organization\",\"name\":\"The Startup\",\"url\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\",\"logo\":{\"@type\":\"ImageObject\",\"width\":350,\"height\":60,\"url\":\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F700\\\\u002F1*IOJrKVmLnRcFz3E_KrrN_Q.png\"}},\"mainEntityOfPage\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fautomatic-image-captioning-using-deep-learning-5e899c127387\"}</script><script data-rh=\"true\" >(function(i,s,o,g,r,a,m){i[\\'GoogleAnalyticsObject\\']=r;i[r]=i[r]||function(){\\n(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\\nm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\\n})(window,document,\\'script\\',\\'https://www.google-analytics.com/analytics.js\\',\\'ga\\');\\nga(\\'create\\', \\'UA-24232453-2\\', \\'auto\\');\\nga(\\'send\\', \\'pageview\\');</script><link rel=\"preload\" href=\"https://cdn.optimizely.com/js/16180790160.js\" as=\"script\"><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"STATIC\">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Oxygen, Ubuntu, Cantarell, \"Open Sans\", \"Helvetica Neue\", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:25px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{position:absolute}.u{top:0}.v{left:0}.w{right:0}.x{z-index:500}.y{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ah{max-width:1192px}.ai{min-width:0}.aj{width:100%}.ak{height:65px}.an{flex:1 0 auto}.ao{fill:rgba(25, 25, 25, 1)}.ap{flex:0 0 auto}.aq{visibility:hidden}.ar{margin-left:16px}.as{color:rgba(132, 133, 133, 1)}.at{fill:rgba(132, 133, 133, 1)}.au{font-size:inherit}.av{border:inherit}.aw{font-family:inherit}.ax{letter-spacing:inherit}.ay{font-weight:inherit}.az{padding:0}.ba{margin:0}.be:disabled{cursor:default}.bf:disabled{color:rgba(163, 208, 162, 0.5)}.bg:disabled{fill:rgba(163, 208, 162, 0.5)}.bh{border-top:none}.bi{background-color:rgba(249, 249, 249, 1)}.bk{height:54px}.bl{overflow:hidden}.bm{margin-right:40px}.bn{height:36px}.bo{width:211px}.bp{overflow:auto}.bq{flex:0 1 auto}.br{list-style-type:none}.bs{line-height:40px}.bt{white-space:nowrap}.bu{overflow-x:auto}.bv{align-items:flex-start}.bw{margin-top:20px}.bx{padding-top:20px}.by{height:80px}.bz{height:20px}.ca{margin-right:15px}.cb{margin-left:15px}.cc:first-child{margin-left:0}.cd{min-width:1px}.ce{background-color:rgba(131, 132, 132, 1)}.cf{font-family:sohne, \"Helvetica Neue\", Helvetica, Arial, sans-serif}.cg{font-size:13px}.ch{line-height:20px}.ci{color:rgba(60, 62, 62, 1)}.cj{text-transform:uppercase}.ck{letter-spacing:1px}.cl{color:inherit}.cm{fill:inherit}.cp:disabled{color:rgba(109, 110, 110, 1)}.cq:disabled{fill:rgba(109, 110, 110, 1)}.cr{margin-bottom:0px}.cs{margin-top:0px}.ct{height:119px}.cw{padding-left:24px}.cx{padding-right:24px}.cy{margin-left:auto}.cz{margin-right:auto}.da{max-width:728px}.db{box-sizing:border-box}.dc{top:calc(100vh + 100px)}.dd{bottom:calc(100vh + 100px)}.de{width:10px}.df{pointer-events:none}.dg{word-break:break-word}.dh{word-wrap:break-word}.di:after{display:block}.dj:after{content:\"\"}.dk:after{clear:both}.dl{max-width:680px}.dm{line-height:1.23}.dn{letter-spacing:0}.do{font-style:normal}.dp{font-family:fell, Georgia, Cambria, \"Times New Roman\", Times, serif}.ek{margin-bottom:-0.27em}.el{color:rgba(41, 41, 41, 1)}.em{margin-top:32px}.en{justify-content:space-between}.er{border-radius:50%}.es{height:48px}.et{width:48px}.eu{margin-left:12px}.ev{font-size:14px}.ew{margin-bottom:2px}.ey{max-height:20px}.ez{text-overflow:ellipsis}.fa{display:-webkit-box}.fb{-webkit-line-clamp:1}.fc{-webkit-box-orient:vertical}.ff:disabled{color:rgba(117, 117, 117, 1)}.fg:disabled{fill:rgba(117, 117, 117, 1)}.fh{margin-left:8px}.fi{color:rgba(255, 255, 255, 1)}.fj{padding:0px 8px 1px}.fk{fill:rgba(255, 255, 255, 1)}.fl{background:rgba(132, 133, 133, 1)}.fm{border-color:rgba(132, 133, 133, 1)}.fp:disabled{cursor:inherit}.fq:disabled{opacity:0.3}.fr:disabled:hover{background:rgba(132, 133, 133, 1)}.fs:disabled:hover{border-color:rgba(132, 133, 133, 1)}.ft{border-radius:4px}.fu{border-width:1px}.fv{border-style:solid}.fw{display:inline-block}.fx{text-decoration:none}.fy{color:rgba(117, 117, 117, 1)}.fz{align-items:flex-end}.gh{padding-right:6px}.gk{fill:rgba(117, 117, 117, 1)}.gl{margin-right:8px}.gm{margin-right:-6px}.gn{box-shadow:inset 3px 0 0 0 rgba(41, 41, 41, 1)}.go{padding-left:23px}.gp{margin-left:-20px}.gq{line-height:1.58}.gr{letter-spacing:-0.004em}.gs{font-style:italic}.gt{font-family:charter, Georgia, Cambria, \"Times New Roman\", Times, serif}.ho{margin-bottom:-0.46em}.hp{font-weight:700}.hq{text-decoration:underline}.hr{max-width:574px}.hx{clear:both}.hy{opacity:0}.hz{transition:opacity 100ms 400ms}.ia{height:100%}.ib{will-change:transform}.ic{transform:translateZ(0)}.id{margin:auto}.ie{position:relative}.if{background-color:rgba(242, 242, 242, 1)}.ig{padding-bottom:52.4390243902439%}.ih{height:0}.ii{filter:blur(20px)}.ij{transform:scale(1.1)}.ik{visibility:visible}.il{list-style-type:disc}.im{margin-left:30px}.in{padding-left:0px}.it{max-width:252px}.iu{padding-bottom:150%}.iv{max-width:620px}.iw{padding-bottom:40.16129032258065%}.ix{max-width:541px}.iy{padding-bottom:52.86506469500924%}.iz{max-width:565px}.ja{padding-bottom:42.47787610619469%}.jb{max-width:615px}.jc{padding-bottom:39.02439024390244%}.jd{max-width:730px}.jf{cursor:zoom-in}.jg{z-index:auto}.ji{padding-bottom:18.21917808219178%}.jj{max-width:564px}.jk{padding-bottom:47.163120567375884%}.jl{max-width:603px}.jm{padding-bottom:78.27529021558873%}.js{box-shadow:inset 0 0 0 1px rgba(230, 230, 230, 1)}.jt{padding:0px}.ju{padding:16px 20px}.jv{flex-direction:column}.jw{flex:1 1 auto}.jy{font-size:20px}.jz{line-height:28px}.ka{max-height:56px}.kb{-webkit-line-clamp:2}.kc{margin-top:8px}.kd{font-size:16px}.ke{max-height:40px}.kf{margin-top:12px}.kg{width:160px}.kh{background-image:url(https://miro.medium.com/max/320/0*6NwyiP-i0fJlh4Bz)}.ki{background-origin:border-box}.kj{background-size:cover}.kk{height:167px}.kl{background-position:50% 50%}.km{max-width:100%}.kn{will-change:opacity}.ko{position:fixed}.kp{width:188px}.kq{left:50%}.kr{transform:translateX(406px)}.ks{top:calc(65px + 54px + 14px)}.kv{top:159px}.kx{width:131px}.ky{font-weight:500}.kz{padding-bottom:28px}.la{border-bottom:1px solid rgba(230, 230, 230, 1)}.lb{padding-bottom:20px}.lc{padding-top:2px}.ld{max-height:120px}.le{-webkit-line-clamp:6}.lf{padding:7px 16px 9px}.lg{flex-direction:row}.lh{padding-top:28px}.li{margin-bottom:19px}.lj{margin-left:-3px}.lp{outline:0}.lq{border:0}.lr{user-select:none}.ls{cursor:pointer}.lt> svg{pointer-events:none}.lv{-webkit-user-select:none}.mf button{text-align:left}.mg{opacity:0.4}.mh{cursor:not-allowed}.mi{padding-right:4px}.mr{margin-top:40px}.ms{flex-wrap:wrap}.mt{margin-top:25px}.mu{margin-bottom:8px}.mv{line-height:22px}.mw{border-radius:3px}.mx{padding:5px 10px}.my{background:rgba(242, 242, 242, 1)}.mz{max-width:155px}.nd{top:1px}.nr{margin-left:-1px}.ns{margin-left:-4px}.oa{padding-right:8px}.ob{padding-top:32px}.oc{border-top:1px solid rgba(230, 230, 230, 1)}.od{margin-bottom:25px}.of{margin-bottom:32px}.og{min-height:80px}.ol{width:80px}.om{padding-left:102px}.oo{line-height:18px}.op{letter-spacing:0.077em}.oq{margin-bottom:6px}.or{font-size:22px}.os{padding:4px 12px 6px}.ot{max-width:555px}.ou{max-width:450px}.ov{line-height:24px}.ow{display:none}.oy{max-width:550px}.oz{padding-top:24px}.pa{margin-top:5px}.pb{height:40px}.pc{width:40px}.pd{font-size:12px}.pe{line-height:16px}.pf{letter-spacing:0.083em}.pg{padding-top:8px}.ph{background:rgba(255, 255, 255, 1)}.pi{margin-bottom:40px}.pj{margin-top:24px}.pk{padding-bottom:16px}.pl{margin-bottom:24px}.rm{flex-grow:0}.rn{padding-bottom:24px}.ro{max-width:500px}.rs{padding-bottom:8px}.sf{padding-bottom:100%}.sq{padding:60px 0}.sr{background-color:rgba(0, 0, 0, 0.9)}.st{padding-bottom:48px}.su{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.sv{margin:0 -12px}.sw{margin:0 12px}.sx{flex:1 1 0}.ta:disabled{color:rgba(255, 255, 255, 0.7)}.tb:disabled{fill:rgba(255, 255, 255, 0.7)}.tc{color:rgba(255, 255, 255, 0.98)}.td{color:rgba(255, 255, 255, 0.7)}.te{height:22px}.tf{width:200px}.tl{margin-right:16px}.bb:hover{cursor:pointer}.bc:hover{color:rgba(113, 114, 114, 1)}.bd:hover{fill:rgba(113, 114, 114, 1)}.cn:hover{color:rgba(46, 47, 48, 1)}.co:hover{fill:rgba(46, 47, 48, 1)}.fe:hover{text-decoration:underline}.fn:hover{background:rgba(113, 114, 114, 1)}.fo:hover{border-color:rgba(113, 114, 114, 1)}.gi:hover{color:rgba(25, 25, 25, 1)}.gj:hover{fill:rgba(25, 25, 25, 1)}.lx:hover{fill:rgba(117, 117, 117, 1)}.sy:hover{color:rgba(255, 255, 255, 0.99)}.sz:hover{fill:rgba(255, 255, 255, 0.99)}.jh:focus{transform:scale(1.01)}.lw:focus{fill:rgba(117, 117, 117, 1)}.lu:active{border-style:none}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (min-width: 1080px)\">.d{display:none}.ag{margin:0 64px}.eg{font-size:48px}.eh{margin-top:0.55em}.ei{line-height:60px}.ej{letter-spacing:-0.011em}.gg{margin-left:30px}.hk{font-size:21px}.hl{margin-top:2em}.hm{line-height:32px}.hn{letter-spacing:-0.003em}.hw{margin-top:56px}.is{margin-top:1.05em}.jr{margin-top:32px}.lo{margin-right:5px}.me{margin-top:5px}.mq{padding-left:6px}.nf{display:inline-block}.nk{margin-left:7px}.nl{margin-top:8px}.nq{width:25px}.ny{padding-left:7px}.nz{top:3px}.qa{font-size:22px}.qb{line-height:28px}.qc{letter-spacing:0}.qp{width:calc(100% + 32px)}.qq{margin-left:-16px}.qr{margin-right:-16px}.ri{padding-left:16px}.rj{padding-right:16px}.rk{flex-basis:25%}.rl{max-width:25%}.sb{font-size:16px}.sc{line-height:20px}.so{min-width:70px}.sp{min-height:70px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 1079.98px)\">.e{display:none}.gf{margin-left:30px}.ln{margin-right:5px}.md{margin-top:5px}.mp{padding-left:6px}.ne{display:inline-block}.ni{margin-left:7px}.nj{margin-top:8px}.np{width:25px}.nw{padding-left:7px}.nx{top:3px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 903.98px)\">.f{display:none}.ge{margin-left:30px}.lm{margin-right:5px}.mc{margin-top:5px}.mn{padding-left:6px}.mo{top:3px}.nc{display:inline-block}.ng{margin-left:7px}.nh{margin-top:8px}.no{width:15px}.nv{padding-left:3px}.rr{margin-right:16px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 727.98px)\">.g{display:none}.al{height:56px}.am{display:flex}.bj{display:block}.cu{margin-bottom:0px}.cv{height:110px}.ep{margin-top:32px}.eq{flex-direction:column-reverse}.gc{margin-bottom:30px}.gd{margin-left:0px}.jx{padding:10px 12px 10px}.ll{margin-left:8px}.ma{margin-top:2px}.mb{margin-right:8px}.ml{padding-left:6px}.mm{top:3px}.nb{display:inline-block}.nn{width:15px}.nu{padding-left:3px}.oe{padding-top:0}.oh{margin-bottom:24px}.oi{align-items:center}.oj{width:102px}.ok{position:relative}.on{padding-left:0}.ox{margin-top:24px}.pm{padding-bottom:12px}.pn{margin-top:16px}.rq{margin-right:16px}.sd{margin-left:16px}.se{margin-right:0px}.ss{padding:32px 0}.tg{width:140px}.th{margin-bottom:16px}.ti{margin-top:30px}.tj{width:100%}.tk{flex-direction:row}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 551.98px)\">.h{display:none}.ab{margin:0 24px}.dq{font-size:34px}.dr{margin-top:0.56em}.ds{line-height:42px}.dt{letter-spacing:-0.016em}.eo{margin-top:32px}.ex{margin-bottom:0px}.ga{margin-bottom:30px}.gb{margin-left:0px}.gu{font-size:18px}.gv{margin-top:1.56em}.gw{line-height:28px}.gx{letter-spacing:-0.003em}.hs{margin-top:40px}.io{margin-top:1.34em}.jn{margin-top:24px}.lk{margin-left:8px}.ly{margin-top:2px}.lz{margin-right:8px}.mj{padding-left:6px}.mk{top:3px}.na{display:inline-block}.nm{width:15px}.nt{padding-left:3px}.po{font-size:20px}.pp{line-height:24px}.pq{letter-spacing:0}.qd{width:calc(100% + 24px)}.qe{margin-left:-12px}.qf{margin-right:-12px}.qs{padding-left:12px}.qt{padding-right:12px}.qu{flex-basis:100%}.qv{max-width:100%}.rp{margin-right:16px}.rt{font-size:16px}.ru{line-height:20px}.sg{min-width:48px}.sh{min-height:48px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (min-width: 904px) and (max-width: 1079.98px)\">.i{display:none}.af{margin:0 64px}.ec{font-size:48px}.ed{margin-top:0.55em}.ee{line-height:60px}.ef{letter-spacing:-0.011em}.hg{font-size:21px}.hh{margin-top:2em}.hi{line-height:32px}.hj{letter-spacing:-0.003em}.hv{margin-top:56px}.ir{margin-top:1.05em}.jq{margin-top:32px}.px{font-size:22px}.py{line-height:28px}.pz{letter-spacing:0}.qm{width:calc(100% + 32px)}.qn{margin-left:-16px}.qo{margin-right:-16px}.re{padding-left:16px}.rf{padding-right:16px}.rg{flex-basis:25%}.rh{max-width:25%}.rz{font-size:16px}.sa{line-height:20px}.sm{min-width:70px}.sn{min-height:70px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (min-width: 728px) and (max-width: 903.98px)\">.j{display:none}.ae{margin:0 48px}.dy{font-size:48px}.dz{margin-top:0.55em}.ea{line-height:60px}.eb{letter-spacing:-0.011em}.hc{font-size:21px}.hd{margin-top:2em}.he{line-height:32px}.hf{letter-spacing:-0.003em}.hu{margin-top:56px}.iq{margin-top:1.05em}.jp{margin-top:32px}.pu{font-size:22px}.pv{line-height:28px}.pw{letter-spacing:0}.qj{width:calc(100% + 28px)}.qk{margin-left:-14px}.ql{margin-right:-14px}.ra{padding-left:14px}.rb{padding-right:14px}.rc{flex-basis:50%}.rd{max-width:50%}.rx{font-size:16px}.ry{line-height:20px}.sk{min-width:48px}.sl{min-height:48px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (min-width: 552px) and (max-width: 727.98px)\">.k{display:none}.ac{margin:0 24px}.du{font-size:34px}.dv{margin-top:0.56em}.dw{line-height:42px}.dx{letter-spacing:-0.016em}.gy{font-size:18px}.gz{margin-top:1.56em}.ha{line-height:28px}.hb{letter-spacing:-0.003em}.ht{margin-top:40px}.ip{margin-top:1.34em}.jo{margin-top:24px}.pr{font-size:20px}.ps{line-height:24px}.pt{letter-spacing:0}.qg{width:calc(100% + 24px)}.qh{margin-left:-12px}.qi{margin-right:-12px}.qw{padding-left:12px}.qx{padding-right:12px}.qy{flex-basis:100%}.qz{max-width:100%}.rv{font-size:16px}.rw{line-height:20px}.si{min-width:48px}.sj{min-height:48px}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"print\">.z{display:none}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"(orientation: landscape) and (max-width: 903.98px)\">.fd{max-height:none}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"(prefers-reduced-motion: no-preference)\">.je{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.kt{transition:opacity 200ms}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 1230px)\">.ku{display:none}</style><style type=\"text/css\" data-fela-rehydration=\"531\" data-fela-type=\"RULE\" media=\"all and (max-width: 1198px)\">.kw{display:none}</style></head><body><div id=\"root\"><div class=\"a b c\"><div class=\"d e f g h i j k\"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = \"about:blank\"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><div class=\"s\"><nav class=\"s t u v w c x y z\"><div><div class=\"s c\"><div class=\"n p\"><div class=\"ab ac ae af ag ah ai aj\"><div class=\"ak n o al am\"><div class=\"n o an x\"><a rel=\"noopener\" href=\"/?source=post_page-----5e899c127387--------------------------------\"><svg viewBox=\"0 0 1043.63 592.71\" class=\"q ao\"><g data-name=\"Layer 2\"><g data-name=\"Layer 1\"><path d=\"M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94\"></path></g></g></svg></a></div><div class=\"s ap x\"><div class=\"n o\"><div class=\"n o g\"><div class=\"aq\" id=\"lo-post-page-navbar-sign-in-link\"><div class=\"ar s\"><span><a href=\"https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_page-----5e899c127387---------------------nav_reg-----------\" class=\"as at au av aw ax ay az ba bb bc bd be bf bg\" rel=\"noopener\">Sign in</a></span></div></div></div></div></div></div></div></div></div><div class=\"bh s bi bj\"><div class=\"n p\"><div class=\"ab ac ae af ag ah ai aj\"><div class=\"bk bl n o\"><div class=\"bm s ap\"><a href=\"/swlh?source=post_page-----5e899c127387--------------------------------\" rel=\"noopener\"><div class=\"bn bo s\"><img alt=\"The Startup\" class=\"\" src=\"https://miro.medium.com/max/422/1*IOJrKVmLnRcFz3E_KrrN_Q.png\" width=\"211\" height=\"36\"/></div></a></div><div class=\"bp s bq\"><ul class=\"br ba bs bt bu n bv g bw bx by\"><li class=\"n o bz ca cb cc\"><span class=\"cf b cg ch ci cj ck\"><a class=\"cl cm au av aw ax ay az ba bb cn co be cp cq\" rel=\"noopener\" href=\"/swlh/when-one-upvote-is-worth-a-thousand-visitors-3e8ed27bcd3e?source=post_page-----5e899c127387--------------------------------\">Submit</a></span></li><span class=\"bz cd ce\"></span><li class=\"n o bz ca cb cc\"><span class=\"cf b cg ch ci cj ck\"><a href=\"https://medium.com/blankpage?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb cn co be cp cq\" rel=\"noopener\">Get smarter at writing</a></span></li></ul></div></div></div></div></div></div></nav><div class=\"cr cs ct s cu cv\"></div><article><section class=\"cw cx cy cz aj da db s\"></section><span class=\"s\"></span><div><div class=\"t v dc dd de df\"></div><section class=\"dg dh di dj dk\"><div class=\"n p\"><div class=\"ab ac ae af ag dl ai aj\"><div class=\"\"><h1 id=\"44f7\" class=\"dm dn do dp b dq dr ds dt du dv dw dx dy dz ea eb ec ed ee ef eg eh ei ej ek el\">Automatic Image Captioning Using Deep Learning</h1><div class=\"em\"><div class=\"n en eo ep eq\"><div class=\"o n\"><div><a rel=\"noopener\" href=\"/@manthan.bhikadiya?source=post_page-----5e899c127387--------------------------------\"><img alt=\"Manthan Bhikadiya\" class=\"s er es et\" src=\"https://miro.medium.com/fit/c/96/96/1*HJ2c7fuPyJGJzb9Hi4veog.jpeg\" width=\"48\" height=\"48\"/></a></div><div class=\"eu aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"ew n o ex\"><span class=\"cf b ev ch bl ey ez fa fb fc fd el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@manthan.bhikadiya?source=post_page-----5e899c127387--------------------------------\">Manthan Bhikadiya</a></span><div class=\"fh s ap h\"><span><button class=\"cf b cg ch fi fj fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\">Follow</button></span></div></div></span></div></div><span class=\"cf b ev ch fy\"><span class=\"cf b ev ch bl ey ez fa fb fc fd fy\"><div><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/swlh/automatic-image-captioning-using-deep-learning-5e899c127387?source=post_page-----5e899c127387--------------------------------\">Oct 5, 2020</a> <!-- -->·<!-- --> <!-- -->7<!-- --> min read</div></span></span></div></div><div class=\"n fz ga gb gc gd ge gf gg z\"><div class=\"n o\"><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on twitter\"><svg width=\"29\" height=\"29\" class=\"gk\"><path d=\"M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z\"></path></svg></button></div><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on linkedin\"><svg width=\"29\" height=\"29\" viewBox=\"0 0 29 29\" fill=\"none\" class=\"gk\"><path d=\"M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z\" fill=\"#fff\"></path></svg></button></div><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on facebook\"><svg width=\"29\" height=\"29\" class=\"gk\"><path d=\"M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79\"></path></svg></button></div><div class=\"gl s\"><div class=\"gk\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_actions_header--------------------------bookmark_preview-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><svg width=\"25\" height=\"25\" viewBox=\"0 0 25 25\"><path d=\"M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z\" fill-rule=\"evenodd\"></path></svg></a></span></div></div><div class=\"gm s an\"></div></div></div></div></div></div><blockquote class=\"gn go gp\"><p id=\"f966\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Overview of Deep Learning:</strong></p></blockquote><p id=\"7539\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Deep learning and Machine learning are the most progressive technologies in this era. Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans. Day by day there is new research in this field. This field is increasing very fast because now we have sufficient computational power for doing this task. Deep learning is a branch of machine learning that uses neural networks with many layers.</p><p id=\"d64f\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"gs\">In traditional machine learning, the algorithm is given a set of relevant features to analyze. However, in deep learning, the algorithm is given raw data and decides for itself what features are relevant. Deep learning networks will often improve as you increase the amount of data being used to train them.</em></strong></p><p id=\"f686\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Read More About Simple Explanation of Deep Learning <a href=\"https://enterprisersproject.com/article/2019/7/deep-learning-explained-plain-english#:~:text=%E2%80%9CDeep%20learning%20is%20a%20branch%20of%20machine%20learning%20that,neural%20networks%20with%20many%20layers.&amp;text=However%2C%20in%20deep%20learning%2C%20the,being%20used%20to%20train%20them.%E2%80%9D\" class=\"cl hq\" rel=\"noopener nofollow\">here</a></p><p id=\"625e\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">There Are some very interesting deep learning applications shown below.</p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz hr\"><div class=\"id s ie if\"><div class=\"ig ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*e4MaH6-Th0pYEPAr.jpg?q=20\" width=\"574\" height=\"301\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"574\" height=\"301\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1148/0*e4MaH6-Th0pYEPAr.jpg\" width=\"574\" height=\"301\" srcSet=\"https://miro.medium.com/max/552/0*e4MaH6-Th0pYEPAr.jpg 276w, https://miro.medium.com/max/1104/0*e4MaH6-Th0pYEPAr.jpg 552w, https://miro.medium.com/max/1148/0*e4MaH6-Th0pYEPAr.jpg 574w\" sizes=\"574px\"/></noscript></div></div></div></figure><p id=\"9be0\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Source:-<a href=\"https://techvidvan.com/tutorials/deep-learning-applications/\" class=\"cl hq\" rel=\"noopener nofollow\">https://techvidvan.com/tutorials/deep-learning-applications/</a></p><p id=\"0501\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Now We will be going to see one of its applications which is Photo descriptions or image captions generator.</p><blockquote class=\"gn go gp\"><p id=\"467c\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Image Captions Generator :</strong></p></blockquote><p id=\"05a5\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Image Caption Generator or Photo Descriptions is one of the Applications of Deep Learning. In Which we have to pass the image to the model and the model does some processing and generating captions or descriptions as per its training. This prediction is sometimes not that much accurate and generates some meaningless sentences. We need very high computational power and a very huge dataset for better results. Now we will see some information about the dataset and the architecture of the neural network of the Image captions generator.</p><blockquote class=\"gn go gp\"><p id=\"8047\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Pre-requisites :</strong></p></blockquote><p id=\"4ef9\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">This project requires good knowledge of Deep learning, Python, working on Jupyter notebooks, Keras library, Numpy, and <em class=\"gs\">Natural language Processing</em></p><p id=\"1f59\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Make sure you have installed all the following necessary libraries:</p><ul class=\"\"><li id=\"8929\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho il im in el\">Tensorflow</li><li id=\"ced5\" class=\"gq gr do gt b gu io gw gx gy ip ha hb hc iq he hf hg ir hi hj hk is hm hn ho il im in el\">Keras</li><li id=\"bd72\" class=\"gq gr do gt b gu io gw gx gy ip ha hb hc iq he hf hg ir hi hj hk is hm hn ho il im in el\">Pandas</li><li id=\"afee\" class=\"gq gr do gt b gu io gw gx gy ip ha hb hc iq he hf hg ir hi hj hk is hm hn ho il im in el\">NumPy</li><li id=\"531d\" class=\"gq gr do gt b gu io gw gx gy ip ha hb hc iq he hf hg ir hi hj hk is hm hn ho il im in el\">nltk ( Natural language tool kit)</li><li id=\"fcfd\" class=\"gq gr do gt b gu io gw gx gy ip ha hb hc iq he hf hg ir hi hj hk is hm hn ho il im in el\">Jupyter- IDE</li></ul><blockquote class=\"gn go gp\"><p id=\"0c5a\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Dataset :</strong></p></blockquote><p id=\"f62e\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">In this project, we are using the flicker 30k dataset. In which it has 30,000 images with image id and a particular id has 5 captions generated.</p><p id=\"ebf5\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Here is the link to the dataset so that you can also download that dataset.</p><p id=\"81ba\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Flicker_30k:- <a href=\"https://www.kaggle.com/hsankesara/flickr-image-dataset\" class=\"cl hq\" rel=\"noopener nofollow\">https://www.kaggle.com/hsankesara/flickr-image-dataset</a></p><p id=\"032b\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">One of the Image in Dataset with ID 1000092795</p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz it\"><div class=\"id s ie if\"><div class=\"iu ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/40/0*VDg65RlgojBJb8dl.jpg?q=20\" width=\"252\" height=\"378\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"252\" height=\"378\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/504/0*VDg65RlgojBJb8dl.jpg\" width=\"252\" height=\"378\"/></noscript></div></div></div></figure><p id=\"ec6b\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">1000092795.jpg</p><p id=\"837e\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Here are the particular captions for these images which is present in the dataset.</p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz iv\"><div class=\"id s ie if\"><div class=\"iw ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*T7NnEfDUrl6y90BV.JPG?q=20\" width=\"620\" height=\"249\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"620\" height=\"249\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1240/0*T7NnEfDUrl6y90BV.JPG\" width=\"620\" height=\"249\" srcSet=\"https://miro.medium.com/max/552/0*T7NnEfDUrl6y90BV.JPG 276w, https://miro.medium.com/max/1104/0*T7NnEfDUrl6y90BV.JPG 552w, https://miro.medium.com/max/1240/0*T7NnEfDUrl6y90BV.JPG 620w\" sizes=\"620px\"/></noscript></div></div></div></figure><blockquote class=\"gn go gp\"><p id=\"f48f\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">The Architecture of Network :</strong></p></blockquote><p id=\"ec00\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"gs\">1 .Image Features Detection :</em></strong></p><p id=\"1df4\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">For image Detecting, we are using a pre-trained model which is VGG16. VGG16 is already installed in the Keras library.VGG 16 was proposed by Karen Simonyan and Andrew Zisserman of the Visual Geometry Group Lab of Oxford University in 2014 in the paper <a href=\"https://neurohive.io/en/popular-networks/vgg16/\" class=\"cl hq\" rel=\"noopener nofollow\">VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.</a></p><p id=\"9bb1\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">This model won the ILSVRC challenge in 2014.</p><p id=\"b1af\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Here is the model representation in 3-D and in 2-D.</p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz ix\"><div class=\"id s ie if\"><div class=\"iy ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*-vdH52g5TwhLPm26.JPG?q=20\" width=\"541\" height=\"286\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"541\" height=\"286\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1082/0*-vdH52g5TwhLPm26.JPG\" width=\"541\" height=\"286\" srcSet=\"https://miro.medium.com/max/552/0*-vdH52g5TwhLPm26.JPG 276w, https://miro.medium.com/max/1082/0*-vdH52g5TwhLPm26.JPG 541w\" sizes=\"541px\"/></noscript></div></div></div></figure><p id=\"239b\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Source:-<a href=\"https://neurohive.io/en/popular-networks/vgg16/\" class=\"cl hq\" rel=\"noopener nofollow\">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz iz\"><div class=\"id s ie if\"><div class=\"ja ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*vuoNCrq7R_s7WCEK.JPG?q=20\" width=\"565\" height=\"240\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"565\" height=\"240\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1130/0*vuoNCrq7R_s7WCEK.JPG\" width=\"565\" height=\"240\" srcSet=\"https://miro.medium.com/max/552/0*vuoNCrq7R_s7WCEK.JPG 276w, https://miro.medium.com/max/1104/0*vuoNCrq7R_s7WCEK.JPG 552w, https://miro.medium.com/max/1130/0*vuoNCrq7R_s7WCEK.JPG 565w\" sizes=\"565px\"/></noscript></div></div></div></figure><p id=\"26f4\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Source:-VGG16 | CNN Model GF<strong class=\"gt hp\"><em class=\"gs\">G</em></strong></p><p id=\"043a\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"gs\">Overview :</em></strong></p><p id=\"70c2\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">The input to conv1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left/right, up/down, center). In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3×3 conv. layers. Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2×2 pixel window, with stride 2.</p><p id=\"038f\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks.</p><p id=\"4baa\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Read More <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" class=\"cl hq\" rel=\"noopener nofollow\">Here</a></p><p id=\"3c83\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"gs\">2. Text Generation using LSTM</em></strong></p><p id=\"3c34\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Long Short Term Memory networks — usually just called “LSTMs” — are a special kind of RNN, capable of learning long-term dependencies. They were introduced by <a href=\"https://www.blogger.com/u/1/blog/post/edit/5255967751950062393/3581114184014589371#\" class=\"cl hq\" rel=\"noopener nofollow\">Hochreiter &amp; Schmidhuber (1997)</a> and were refined and popularized by many people in the following work. They work tremendously well on a large variety of problems and are now widely used.</p><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz jb\"><div class=\"id s ie if\"><div class=\"jc ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*9ITR9tOQlCSyWmKH.JPG?q=20\" width=\"615\" height=\"240\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"615\" height=\"240\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1230/0*9ITR9tOQlCSyWmKH.JPG\" width=\"615\" height=\"240\" srcSet=\"https://miro.medium.com/max/552/0*9ITR9tOQlCSyWmKH.JPG 276w, https://miro.medium.com/max/1104/0*9ITR9tOQlCSyWmKH.JPG 552w, https://miro.medium.com/max/1230/0*9ITR9tOQlCSyWmKH.JPG 615w\" sizes=\"615px\"/></noscript></div></div></div></figure><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div role=\"button\" tabindex=\"0\" class=\"je jf ie jg aj jh\"><div class=\"cy cz jd\"><div class=\"id s ie if\"><div class=\"ji ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*kp29KmqfPXMdCckPAb4I3Q.jpeg?q=20\" width=\"730\" height=\"133\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"730\" height=\"133\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1460/1*kp29KmqfPXMdCckPAb4I3Q.jpeg\" width=\"730\" height=\"133\" srcSet=\"https://miro.medium.com/max/552/1*kp29KmqfPXMdCckPAb4I3Q.jpeg 276w, https://miro.medium.com/max/1104/1*kp29KmqfPXMdCckPAb4I3Q.jpeg 552w, https://miro.medium.com/max/1280/1*kp29KmqfPXMdCckPAb4I3Q.jpeg 640w, https://miro.medium.com/max/1400/1*kp29KmqfPXMdCckPAb4I3Q.jpeg 700w\" sizes=\"700px\"/></noscript></div></div></div></div></figure><p id=\"21d1\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Source:-<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" class=\"cl hq\" rel=\"noopener nofollow\">LSTM Networks</a></p><p id=\"4ba3\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"gs\">Overview :</em></strong></p><p id=\"56d6\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">A common LSTM unit is composed of a <strong class=\"gt hp\">cell</strong>, an <strong class=\"gt hp\">input gate</strong>, an <strong class=\"gt hp\">output gate</strong> and a <strong class=\"gt hp\">forget gate</strong>. The cell remembers values over arbitrary time intervals and the three <em class=\"gs\">gates</em> regulate the flow of information into and out of the cell.</p><p id=\"2279\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">LSTM networks are well-suited to classifying, processing, and making predictions based on time series data since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models, and other sequence learning methods in numerous applications.</p><p id=\"cf56\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">The advantage of an LSTM cell compared to a common recurrent unit is its cell memory unit. The cell vector has the ability to encapsulate the notion of forgetting part of its previously-stored memory, as well as to add part of the new information. To illustrate this, one has to inspect the equations of the cell and the way it processes sequences under the hood.</p><p id=\"7a96\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Now we are combining this model architecture in one model and that is our final model which will generate caption from images.</p><p id=\"6d0d\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Read Wikipedia:-<a href=\"https://en.wikipedia.org/wiki/Long_short-term_memory\" class=\"cl hq\" rel=\"noopener nofollow\">LSTM Networks Full explained</a></p><blockquote class=\"gn go gp\"><p id=\"a714\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Main Model Architecture:</strong></p></blockquote><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz jj\"><div class=\"id s ie if\"><div class=\"jk ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*ENpcH_oTsR4CNlNg.png?q=20\" width=\"564\" height=\"266\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"564\" height=\"266\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1128/0*ENpcH_oTsR4CNlNg.png\" width=\"564\" height=\"266\" srcSet=\"https://miro.medium.com/max/552/0*ENpcH_oTsR4CNlNg.png 276w, https://miro.medium.com/max/1104/0*ENpcH_oTsR4CNlNg.png 552w, https://miro.medium.com/max/1128/0*ENpcH_oTsR4CNlNg.png 564w\" sizes=\"564px\"/></noscript></div></div></div></figure><p id=\"ad61\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">This final model is a combination of CNN and RNN models. To train this model we have to give two inputs two the models. (1) Images (2) Corresponding Captions. For each LSTM layer, we input one word for each LSTM layer, and each LSTM layer predicts the next word, and that how the LSTM model optimizes itself by learning from captions. For Image features, we are getting All image features array from the VGG16 pre-trained model and saved in a file so that we can use this file or features directly to correlate captions and image features with each other. Finally the image features and LSTM last layer we input this both outputs combination into decoder model in which we are adding both image features and captions so that model learns to generate captions from images and for a final layer we generate output or captions which length is the maximum length of dataset captions.</p><p id=\"7fa2\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">The last layer has a size of the length of the vocab. For this model, we are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words. We are using Adam optimizer for optimization of the network or update the weights of the network.</p><blockquote class=\"gn go gp\"><p id=\"6922\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\"><em class=\"do\">Bleu Score :</em></strong></p></blockquote><p id=\"0af7\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">We can generate captions with the n-grams model for that purpose we are using Blue-score for this model. By using BLEU Score we can check which n-gram is best to generate captions for this dataset.BLEU Score lies between 0 and 1. BLEU, or the <strong class=\"gt hp\">Bilingual Evaluation Understudy</strong>, is a score for comparing a candidate translation of the text to one or more reference translations. Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks.</p><blockquote class=\"gn go gp\"><p id=\"9605\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Model Summary :</strong></p></blockquote><figure class=\"hs ht hu hv hw hx cy cz paragraph-image\"><div class=\"cy cz jl\"><div class=\"id s ie if\"><div class=\"jm ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img alt=\"Image for post\" class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*LVF9PPW57DSPZ_lf.JPG?q=20\" width=\"603\" height=\"472\"/></div><img alt=\"Image for post\" class=\"hy hz t u v ia aj c\" width=\"603\" height=\"472\"/><noscript><img alt=\"Image for post\" class=\"t u v ia aj\" src=\"https://miro.medium.com/max/1206/0*LVF9PPW57DSPZ_lf.JPG\" width=\"603\" height=\"472\" srcSet=\"https://miro.medium.com/max/552/0*LVF9PPW57DSPZ_lf.JPG 276w, https://miro.medium.com/max/1104/0*LVF9PPW57DSPZ_lf.JPG 552w, https://miro.medium.com/max/1206/0*LVF9PPW57DSPZ_lf.JPG 603w\" sizes=\"603px\"/></noscript></div></div></div></figure><blockquote class=\"gn go gp\"><p id=\"b75f\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Github:</strong></p></blockquote><div class=\"jn jo jp jq jr js\"><a href=\"https://github.com/manthan89-py/Image-Caption-Generator\" target=\"_blank\" rel=\"noopener nofollow\"><div class=\"jt n ap\"><div class=\"ju n jv p jw jx\"><h2 class=\"dp b jy jz bl ka ez fa kb fc fd dn el\">manthan89-py/Image-Caption-Generator</h2><div class=\"kc s\"><h3 class=\"cf b kd ch bl ke ez fa kb fc fd fy\">For this Projet you must have a complete understanding of CNN, LSTM and Transfer learning You can also check for my blog…</h3></div><div class=\"kf s\"><p class=\"cf b cg ch bl ke ez fa kb fc fd fy\">github.com</p></div></div><div class=\"kg s\"><div class=\"kh s ki kj kk kg kl km js\"></div></div></div></a></div><p id=\"7ee2\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Also, check out my other projects and if you find it useful then don’t forget to give a star.</p><blockquote class=\"gn go gp\"><p id=\"4ef2\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Conclusion :</strong></p></blockquote><p id=\"018a\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\">Finally, conclude this project we understand VGG16 model Architecture, Long short term memory Network, how to combine this both model, bleu score, How the LSTM network generates captions, How the VGG16 model we can use for our project, and how to generate captions from images using deep learning.</p><blockquote class=\"gn go gp\"><p id=\"2e67\" class=\"gq gr gs gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">More Blogs On Image Captions</strong>:</p></blockquote><p id=\"588a\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><a class=\"cl hq\" rel=\"noopener\" href=\"/swlh/image-captioning-in-python-with-keras-870f976e0f18\">Image Captioning in Python with Keras</a></p><p id=\"f837\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><a class=\"cl hq\" rel=\"noopener\" href=\"/swlh/image-captioning-using-attention-mechanism-f3d7fc96eb0e\">Image Caption Using Attention Mechanism</a></p><p id=\"4450\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><a href=\"https://towardsdatascience.com/automatic-image-captioning-with-cnn-rnn-aae3cd442d83\" class=\"cl hq\" rel=\"noopener\">Automatic Image Captioning With CNN and RNN</a></p><p id=\"70a9\" class=\"gq gr do gt b gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho dg el\"><strong class=\"gt hp\">Thanks for reading! If you enjoyed this article, please hit the clap button as many times as you can. It would mean a lot and encourage me to keep sharing my knowledge.</strong></p></div></div></section></div></article><div class=\"hy df ko kn aj kv kt kw\" data-test-id=\"post-sidebar\"><div class=\"n p\"><div class=\"ab ac ae af ag ah ai aj\"><div class=\"kx n jv\"><div class=\"df\"><div><div class=\"kz la s\"><a href=\"/swlh?source=post_sidebar--------------------------post_sidebar-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><h2 class=\"cf ky kd ch dn el dg\">The Startup</h2></a><div class=\"lb lc s\"><p class=\"cf b ev ch bl ld ez fa le fc fd fy\">Medium&#x27;s largest active publication, followed by +768K people. Follow to join our community.</p></div><div class=\"fw\" aria-hidden=\"false\" aria-describedby=\"collectionFollowPopover\" aria-labelledby=\"collectionFollowPopover\"><span><button class=\"cf b ev ch fi lf fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\"><div class=\"n lg\">Follow</div></button></span></div></div><div class=\"lh li lj n\"><div class=\"n o\"><div class=\"s ie lk ll lm ln lo\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_sidebar-----5e899c127387---------------------clap_sidebar-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><div class=\"az lp lq lr ls lt lu lv r lw lx\"><svg width=\"29\" height=\"29\" aria-label=\"clap\"><g fill-rule=\"evenodd\"><path d=\"M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z\"></path></g></svg></div></a></span></div><div class=\"s ly lz ma mb mc md me\"><div class=\"mf\"><p class=\"cf b ev ch fy\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\">58<!-- --> </button></p></div></div></div></div><div class=\"li s\"><button class=\"ls lq az\"><div class=\"mi n o lg\"><svg width=\"25\" height=\"25\" class=\"r\" aria-label=\"responses\"><path d=\"M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z\" fill-rule=\"evenodd\"></path></svg><div class=\"s ie mj mk ml mm mn mo mp mq\"></div></div></button></div><div class=\"gk\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_sidebar-----5e899c127387---------------------bookmark_sidebar-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><svg width=\"25\" height=\"25\" viewBox=\"0 0 25 25\"><path d=\"M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z\" fill-rule=\"evenodd\"></path></svg></a></span></div></div></div></div></div></div></div><div class=\"hy df kn ko kp kq kr ks kt ku\"></div><div><div class=\"mr hx n jv p\"><div class=\"n p\"><div class=\"ab ac ae af ag dl ai aj\"><div class=\"n ms\"></div><div class=\"n o ms\"></div><div class=\"mt s\"><ul class=\"az ba\"><li class=\"fw br gl mu\"><a href=\"https://medium.com/swlh/tagged/image-captioning\" class=\"cf b cg mv fy mw mx fx s my\">Image Captioning</a></li><li class=\"fw br gl mu\"><a href=\"https://medium.com/swlh/tagged/machine-learning\" class=\"cf b cg mv fy mw mx fx s my\">Machine Learning</a></li><li class=\"fw br gl mu\"><a href=\"https://medium.com/swlh/tagged/deep-learning\" class=\"cf b cg mv fy mw mx fx s my\">Deep Learning</a></li><li class=\"fw br gl mu\"><a href=\"https://medium.com/swlh/tagged/computer-vision\" class=\"cf b cg mv fy mw mx fx s my\">Computer Vision</a></li><li class=\"fw br gl mu\"><a href=\"https://medium.com/swlh/tagged/naturallanguageprocessing\" class=\"cf b cg mv fy mw mx fx s my\">Naturallanguageprocessing</a></li></ul></div><div class=\"mt n en z\"><div class=\"n lg\"><div class=\"mz s\"><span class=\"s na nb nc e d\"><div class=\"n o\"><div class=\"s ie lk ll lm ln lo\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_actions_footer-----5e899c127387---------------------clap_footer-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><div class=\"az lp lq lr ls lt lu lv r lw lx\"><svg width=\"25\" height=\"25\" viewBox=\"0 0 25 25\" aria-label=\"clap\"><g fill-rule=\"evenodd\"><path d=\"M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z\"></path></g></svg></div></a></span></div><div class=\"s ly lz ma mb mc md me\"><div class=\"ie nd mf\"><p class=\"cf b ev ch el\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\">58<span class=\"s h g f ne nf\">\\xa0<!-- -->claps</span></button><span class=\"s h g f ne nf\"></span></p></div></div></div></span><span class=\"s h g f ne nf\"><div class=\"n bv\"><div class=\"s ie lk ll\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_actions_footer-----5e899c127387---------------------clap_footer-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><div class=\"az lp lq lr ls lt lu lv r lw lx\"><svg width=\"33\" height=\"33\" viewBox=\"0 0 33 33\" aria-label=\"clap\"><path d=\"M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z\" fill-rule=\"evenodd\"></path></svg></div></a></span></div><div class=\"s ly lz ma mb ng nh ni nj nk nl\"><div class=\"ie nd mf\"><p class=\"cf b ev ch el\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\">58<span class=\"s h g f ne nf\">\\xa0<!-- -->claps</span></button><span class=\"s h g f ne nf\"></span></p></div></div></div></span></div><div class=\"s nm nn no np nq\"></div><button class=\"ls lq az\"><div class=\"mi n o lg\"><span class=\"nr s h g f ne nf\"><svg width=\"33\" height=\"33\" viewBox=\"0 0 33 33\" fill=\"none\" class=\"r\" aria-label=\"responses\"><path clip-rule=\"evenodd\" d=\"M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z\"></path></svg></span><span class=\"ns s na nb nc e d\"><svg width=\"25\" height=\"25\" class=\"r\" aria-label=\"responses\"><path d=\"M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z\" fill-rule=\"evenodd\"></path></svg></span><div class=\"s ie nt mk nu mm nv mo nw nx ny nz\"></div></div></button></div><div class=\"n o\"><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on twitter\"><svg width=\"29\" height=\"29\" class=\"gk\"><path d=\"M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z\"></path></svg></button></div><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on linkedin\"><svg width=\"29\" height=\"29\" viewBox=\"0 0 29 29\" fill=\"none\" class=\"gk\"><path d=\"M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z\" fill=\"#fff\"></path></svg></button></div><div class=\"gh s ap\"><button class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" aria-label=\"Share on facebook\"><svg width=\"29\" height=\"29\" class=\"gk\"><path d=\"M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79\"></path></svg></button></div><div class=\"oa s ap\"><div class=\"gk\"><span><a href=\"https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F5e899c127387&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fautomatic-image-captioning-using-deep-learning-5e899c127387&amp;source=post_actions_footer--------------------------bookmark_footer-----------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\"><svg width=\"25\" height=\"25\" viewBox=\"0 0 25 25\"><path d=\"M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z\" fill-rule=\"evenodd\"></path></svg></a></span></div></div></div></div></div></div><div><div class=\"n p\"><div class=\"ab ac ae af ag dl ai aj\"><div class=\"ob oc od mt s oe z\"><div class=\"s g\"><div class=\"of og s ie\"><span class=\"s oh am oi\"><div class=\"s t oj ok\"><a rel=\"noopener\" href=\"/@manthan.bhikadiya?source=follow_footer-------------------------------------\"><img alt=\"Manthan Bhikadiya\" class=\"s er by ol\" src=\"https://miro.medium.com/fit/c/160/160/1*HJ2c7fuPyJGJzb9Hi4veog.jpeg\" width=\"80\" height=\"80\"/></a></div><span class=\"s\"><div class=\"om s on\"><p class=\"cf b cg oo op fy cj\">Written by</p></div><div class=\"om oq n on\"><div class=\"aj n o en\"><h2 class=\"cf ky or jz dn el\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\" href=\"/@manthan.bhikadiya?source=follow_footer-------------------------------------\">Manthan Bhikadiya</a></h2><div class=\"s g\"><span><button class=\"cf b ev ch fi os fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\">Follow</button></span></div></div></div></span></span><div class=\"om ot s on bj\"><div class=\"ou s\"><p class=\"cf b kd ov fy\"></p></div><div class=\"ow ox bj\"><span><button class=\"cf b ev ch fi os fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\">Follow</button></span></div></div></div><div class=\"ob s\"></div><div class=\"of og s ie\"><span class=\"s oh am oi\"><div class=\"s t oj ok\"><a href=\"/swlh?source=follow_footer-------------------------------------\" rel=\"noopener\"><img alt=\"The Startup\" class=\"ft ol by\" src=\"https://miro.medium.com/fit/c/160/160/1*Xd2uZaVHfrGOP14W_3UQRg.jpeg\" width=\"80\" height=\"80\"/></a></div><span class=\"s\"><div class=\"om oq n on\"><div class=\"aj n o en\"><h2 class=\"cf ky or jz dn el\"><a href=\"/swlh?source=follow_footer-------------------------------------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\">The Startup</a></h2><div class=\"s g\"><div class=\"fw\" aria-hidden=\"false\" aria-describedby=\"collectionFollowPopover\" aria-labelledby=\"collectionFollowPopover\"><span><button class=\"cf b ev ch fi os fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\"><div class=\"n lg\">Follow</div></button></span></div></div></div></div></span></span><div class=\"om oy s on bj\"><div class=\"ou s\"><p class=\"cf b kd ov fy\">Medium&#x27;s largest active publication, followed by +768K people. Follow to join our community.</p></div><div class=\"ow ox bj\"><div class=\"fw\" aria-hidden=\"false\" aria-describedby=\"collectionFollowPopover\" aria-labelledby=\"collectionFollowPopover\"><span><button class=\"cf b ev ch fi os fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\"><div class=\"n lg\">Follow</div></button></span></div></div></div></div></div><div class=\"ow bj\"><div class=\"oz s\"><div class=\"n lg\"><div class=\"pa s\"><a rel=\"noopener\" href=\"/@manthan.bhikadiya?source=follow_footer-------------------------------------\"><img alt=\"Manthan Bhikadiya\" class=\"s er pb pc\" src=\"https://miro.medium.com/fit/c/80/80/1*HJ2c7fuPyJGJzb9Hi4veog.jpeg\" width=\"40\" height=\"40\"/></a></div><div class=\"eu s\"><p class=\"cf b pd pe pf fy cj\">Written by</p><div class=\"n lg\"><h2 class=\"cf ky kd ch dn el\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\" href=\"/@manthan.bhikadiya?source=follow_footer-------------------------------------\">Manthan Bhikadiya</a></h2><div class=\"eu s\"><span><button class=\"cf b cg ch fi fj fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\">Follow</button></span></div></div><div class=\"pg s\"><p class=\"cf b ev ch fy\"></p></div></div></div><div class=\"oz s\"><div class=\"n lg\"><a href=\"/swlh?source=follow_footer-------------------------------------\" rel=\"noopener\"><img alt=\"The Startup\" class=\"ft pc pb\" src=\"https://miro.medium.com/fit/c/80/80/1*Xd2uZaVHfrGOP14W_3UQRg.jpeg\" width=\"40\" height=\"40\"/></a><div class=\"eu s\"><div class=\"n lg\"><h2 class=\"cf ky kd ch dn el\"><a href=\"/swlh?source=follow_footer-------------------------------------\" class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg\" rel=\"noopener\">The Startup</a></h2><div class=\"eu s\"><div class=\"fw\" aria-hidden=\"false\" aria-describedby=\"collectionFollowPopover\" aria-labelledby=\"collectionFollowPopover\"><span><button class=\"cf b cg ch fi fj fk fl fm fn fo bb fp fq fr fs ft fu fv db fw fx\"><div class=\"n lg\">Follow</div></button></span></div></div></div><div class=\"pg s\"><p class=\"cf b ev ch fy\">Medium&#x27;s largest active publication, followed by +768K people. Follow to join our community.</p></div></div></div></div></div></div></div></div></div><div class=\"s ph z\"><div class=\"n p\"><div class=\"ab ac ae af ag ah ai aj\"><div class=\"pi pj s\"><div class=\"pk la pl pj s pm pn\"><h2 class=\"cf ky po pp pq pr ps pt pu pv pw px py pz qa qb qc el\">More From Medium</h2></div><div class=\"bv n lg ms qd qe qf qg qh qi qj qk ql qm qn qo qp qq qr\"><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/data-from-the-trenches/narrowing-the-search-which-hyperparameters-really-matter-5e984ab760be?source=post_internal_links---------0----------------------------\">Narrowing the Search: Which Hyperparameters Really Matter?</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@aimee.coelho_27638?source=post_internal_links---------0----------------------------\">Aimee Coelho</a><span> <!-- -->in<!-- --> <a href=\"/data-from-the-trenches?source=post_internal_links---------0----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">data from the trenches</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/data-from-the-trenches/narrowing-the-search-which-hyperparameters-really-matter-5e984ab760be?source=post_internal_links---------0----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/swlh/solutions-for-a-dice-game-5eabb6487b9b?source=post_internal_links---------1----------------------------\">Solutions for a Dice Game</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a href=\"https://matepocs.medium.com/?source=post_internal_links---------1----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">Mate Pocs</a><span> <!-- -->in<!-- --> <a href=\"/swlh?source=post_internal_links---------1----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">The Startup</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/swlh/solutions-for-a-dice-game-5eabb6487b9b?source=post_internal_links---------1----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*gp1hjJ3ENY5SuKRljl62jg.jpeg?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*gp1hjJ3ENY5SuKRljl62jg.jpeg\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*gp1hjJ3ENY5SuKRljl62jg.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*gp1hjJ3ENY5SuKRljl62jg.jpeg 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/swlh/star-wars-an-nlp-adventure-5e0deb70cd75?source=post_internal_links---------2----------------------------\">Star Wars: An NLP Adventure</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@oliviermichaud_62658?source=post_internal_links---------2----------------------------\">Olivier Michaud</a><span> <!-- -->in<!-- --> <a href=\"/swlh?source=post_internal_links---------2----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">The Startup</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/swlh/star-wars-an-nlp-adventure-5e0deb70cd75?source=post_internal_links---------2----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*egs26dtg9ilc8KfYxmp2dg.jpeg?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*egs26dtg9ilc8KfYxmp2dg.jpeg\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*egs26dtg9ilc8KfYxmp2dg.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*egs26dtg9ilc8KfYxmp2dg.jpeg 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/x8-the-ai-community/a-7-minute-introduction-to-lstm-5e1480e6f52a?source=post_internal_links---------3----------------------------\">A 7 Minute Introduction to LSTM</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@prateekkarkare?source=post_internal_links---------3----------------------------\">Prateek Karkare</a><span> <!-- -->in<!-- --> <a href=\"/x8-the-ai-community?source=post_internal_links---------3----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">AI Graduate</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/x8-the-ai-community/a-7-minute-introduction-to-lstm-5e1480e6f52a?source=post_internal_links---------3----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*ZWEMdg-4KzYyCdWr?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/0*ZWEMdg-4KzYyCdWr\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/0*ZWEMdg-4KzYyCdWr 48w, https://miro.medium.com/fit/c/140/140/0*ZWEMdg-4KzYyCdWr 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/datadriveninvestor/assessing-the-risk-of-a-trading-strategy-using-monte-carlo-analysis-in-r-5df55782b21b?source=post_internal_links---------4----------------------------\">Assessing the risk of a trading strategy using Monte Carlo analysis in R</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@gianlucamalato?source=post_internal_links---------4----------------------------\">Gianluca Malato</a><span> <!-- -->in<!-- --> <a href=\"https://medium.datadriveninvestor.com/?source=post_internal_links---------4----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener nofollow\">Data Driven Investor</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/datadriveninvestor/assessing-the-risk-of-a-trading-strategy-using-monte-carlo-analysis-in-r-5df55782b21b?source=post_internal_links---------4----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/swlh/midi-mashups-using-machine-learning-to-generate-unique-musical-scores-6041b6270883?source=post_internal_links---------5----------------------------\">MIDI Mashups: Using Machine Learning to Generate Unique Musical Scores</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@matthew.p.ellis23?source=post_internal_links---------5----------------------------\">Matthew Ellis</a><span> <!-- -->in<!-- --> <a href=\"/swlh?source=post_internal_links---------5----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">The Startup</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/swlh/midi-mashups-using-machine-learning-to-generate-unique-musical-scores-6041b6270883?source=post_internal_links---------5----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*N04OvC-wThS6M3rAfJ2VQA.jpeg?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*N04OvC-wThS6M3rAfJ2VQA.jpeg\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*N04OvC-wThS6M3rAfJ2VQA.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*N04OvC-wThS6M3rAfJ2VQA.jpeg 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/tebs-lab/gradient-descent-604f6d6c116d?source=post_internal_links---------6----------------------------\">Gradient Descent</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@TebbaVonMathenstien?source=post_internal_links---------6----------------------------\">Tyler Elliot Bettilyon</a><span> <!-- -->in<!-- --> <a href=\"/tebs-lab?source=post_internal_links---------6----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">Teb’s Lab</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/tebs-lab/gradient-descent-604f6d6c116d?source=post_internal_links---------6----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/0*iJ-vV9uXKugUhLfz?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/0*iJ-vV9uXKugUhLfz\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/0*iJ-vV9uXKugUhLfz 48w, https://miro.medium.com/fit/c/140/140/0*iJ-vV9uXKugUhLfz 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div><div class=\"qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm\"><div class=\"rn ro s\"><div class=\"aj ia\"><div class=\"n en\"><div class=\"s bq rp rq rr\"><div class=\"rs s\"><h2 class=\"cf ky rt ru pq rv rw pt rx ry pw rz sa pz sb sc qc el\"><a rel=\"noopener\" href=\"/swlh/a-non-technical-explanation-of-image-classifiers-5f9a4cc94224?source=post_internal_links---------7----------------------------\">The Non-Coder’s Guide to Image Classification</a></h2></div><div class=\"o n\"><div></div><div class=\"aj s\"><div class=\"n\"><div style=\"flex:1\"><span class=\"cf b ev ch el\"><div class=\"cr n o ex\"><span class=\"cf b cg ch el\"><a class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\" href=\"/@margueritesiboni?source=post_internal_links---------7----------------------------\">Marguerite Siboni</a><span> <!-- -->in<!-- --> <a href=\"/swlh?source=post_internal_links---------7----------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ff fg\" rel=\"noopener\">The Startup</a></span></span></div></span></div></div></div></div></div><div class=\"eu gl s sd se\"><a class=\"cl cm au av aw ax ay az ba bb gi gj be ff fg s\" rel=\"noopener\" href=\"/swlh/a-non-technical-explanation-of-image-classifiers-5f9a4cc94224?source=post_internal_links---------7----------------------------\"><div class=\"id s ie if\"><div class=\"sf ih s\"><div class=\"hy hz t u v ia aj bl ib ic\"><img class=\"t u v ia aj ii ij ik\" src=\"https://miro.medium.com/max/60/1*zzSHIQU2O3jhxLXpmr68EA.png?q=20\" width=\"70\" height=\"70\" role=\"presentation\"/></div><img class=\"hy hz sg sh si sj sk sl sm sn so sp c\" width=\"70\" height=\"70\" role=\"presentation\"/><noscript><img class=\"sg sh si sj sk sl sm sn so sp\" src=\"https://miro.medium.com/fit/c/140/140/1*zzSHIQU2O3jhxLXpmr68EA.png\" width=\"70\" height=\"70\" srcSet=\"https://miro.medium.com/fit/c/96/140/1*zzSHIQU2O3jhxLXpmr68EA.png 48w, https://miro.medium.com/fit/c/140/140/1*zzSHIQU2O3jhxLXpmr68EA.png 70w\" sizes=\"70px\" role=\"presentation\"/></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sq s sr ss\"><div class=\"n p\"><div class=\"ab ac ae af ag ah ai aj\"><div class=\"st su of n en g\"><div class=\"sv n en\"><div class=\"sw s sx\"><div class=\"rs s\"><a href=\"https://medium.com/about?autoplay=1&amp;source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener\"><h2 class=\"cf ky jy ov dn tc\">Learn more.</h2></a></div><p class=\"cf b ev ch td\">Medium<!-- --> is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface.<!-- --> <a href=\"https://medium.com/about?autoplay=1&amp;source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb be ta tb hq\" rel=\"noopener\">Learn more</a></p></div><div class=\"sw s sx\"><div class=\"rs s\"><a href=\"https://medium.com/topics?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener\"><h2 class=\"cf ky jy ov dn tc\">Make <!-- -->Medium<!-- --> yours.</h2></a></div><p class=\"cf b ev ch td\">Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox.<!-- --> <a href=\"https://medium.com/topics?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb be ta tb hq\" rel=\"noopener\">Explore</a></p></div><div class=\"sw s sx\"><div class=\"rs s\"><a href=\"https://about.medium.com/creators/?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener\"><h2 class=\"cf ky jy ov dn tc\">Share your thinking.</h2></a></div><p class=\"cf b ev ch td\">If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic.<!-- --> <a href=\"https://about.medium.com/creators/?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb be ta tb hq\" rel=\"noopener\">Write on <!-- -->Medium</a></p></div></div></div><div class=\"n jv\"><div class=\"n o en\"><a class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener\" href=\"/?source=post_page-----5e899c127387--------------------------------\"><svg viewBox=\"0 0 3940 610\" class=\"fk te\"><path d=\"M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z\"></path></svg></a><p class=\"cf b ev ch td\"><div class=\"pg tf n en tg am\"><p class=\"cf b kd ov tc\"><a href=\"https://medium.com/about?autoplay=1&amp;source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ta tb\" rel=\"noopener\">About</a></p><p class=\"cf b kd ov tc\"><a href=\"https://help.medium.com/hc/en-us?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ta tb\" rel=\"noopener\">Help</a></p><p class=\"cf b kd ov tc\"><a href=\"https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb fe be ta tb\" rel=\"noopener\">Legal</a></p></div></p></div><div class=\"ow th ti am\"><p class=\"cf b kd ov td\">Get the Medium app</p></div><div class=\"ow th tj am tk\"><div class=\"tl s\"><a href=\"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener nofollow\"><img alt=\"A button that says &#x27;Download on the App Store&#x27;, and if clicked it will lead you to the iOS App store\" class=\"\" src=\"https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png\" width=\"135\" height=\"41\"/></a></div><div class=\"s\"><a href=\"https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----5e899c127387--------------------------------\" class=\"cl cm au av aw ax ay az ba bb sy sz be ta tb\" rel=\"noopener nofollow\"><img alt=\"A button that says &#x27;Get it on, Google Play&#x27;, and if clicked it will lead you to the Google Play store\" class=\"\" src=\"https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png\" width=\"135\" height=\"41\"/></a></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = \"main-20210219-221747-8eb49e9331\"</script><script>window.__GRAPHQL_URI__ = \"https://medium.com/_/graphql\"</script><script>window.__PRELOADED_STATE__ = {\"auroraPage\":{\"isAuroraPageEnabled\":false},\"bookReader\":{\"reader\":{\"currentAsset\":null,\"settingsPanelIsOpen\":false,\"settings\":{\"fontFamily\":\"SANS_SERIF_1\",\"fontScale\":\"M\",\"publisherStyling\":true,\"textAlignment\":\"START\",\"theme\":\"White\"}}},\"cache\":{\"experimentGroupSet\":true,\"group\":\"control\",\"tags\":[],\"serverVariantState\":\"\"},\"client\":{\"isBot\":false,\"isEu\":false,\"isUs\":false,\"isNativeMedium\":false,\"isSafariMobile\":false,\"isSafari\":false,\"inAppBrowserName\":\"\",\"routingEntity\":{\"type\":\"DEFAULT\",\"explicit\":false},\"supportsWebp\":false},\"config\":{\"nodeEnv\":\"production\",\"version\":\"main-20210219-221747-8eb49e9331\",\"isTaggedVersion\":false,\"target\":\"production\",\"productName\":\"Medium\",\"publicUrl\":\"https:\\\\u002F\\\\u002Fcdn-client.medium.com\\\\u002Flite\",\"authDomain\":\"medium.com\",\"authGoogleClientId\":\"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com\",\"favicon\":\"production\",\"glyphUrl\":\"https:\\\\u002F\\\\u002Fglyph.medium.com\",\"branchKey\":\"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm\",\"lightStep\":{\"name\":\"lite-web\",\"host\":\"lightstep.medium.systems\",\"token\":\"ce5be895bef60919541332990ac9fef2\",\"appVersion\":\"main-20210219-221747-8eb49e9331\"},\"algolia\":{\"appId\":\"MQ57UUUQZ2\",\"apiKeySearch\":\"394474ced050e3911ae2249ecc774921\",\"indexPrefix\":\"medium_\",\"host\":\"-dsn.algolia.net\"},\"recaptchaKey\":\"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk\",\"recaptcha3Key\":\"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5\",\"datadog\":{\"clientToken\":\"pub853ea8d17ad6821d9f8f11861d23dfed\",\"context\":{\"deployment\":{\"target\":\"production\",\"tag\":\"main-20210219-221747-8eb49e9331\",\"commit\":\"8eb49e9331b02ebb60c5fb72c647c8dc1160ad3c\"}},\"datacenter\":\"us\"},\"isAmp\":false,\"googleAnalyticsCode\":\"UA-24232453-2\",\"signInWallCustomDomainCollectionIds\":[\"3a8144eabfe3\",\"336d898217ee\",\"61061eb0c96b\",\"138adf9c44c\",\"819cc2aaeee0\"],\"mediumOwnedAndOperatedCollectionIds\":[\"544c7006046e\",\"bcc38c8f6edf\",\"444d13b52878\",\"8d6b8a439e32\",\"92d2092dc598\",\"1285ba81cada\",\"cb8577c9149e\",\"8ccfed20cbb2\",\"ae2a65f35510\",\"3f6ecf56618\",\"7b6769f2748b\",\"fc8964313712\",\"ef8e90590e66\",\"191186aaafa0\",\"d944778ce714\",\"bdc4052bbdba\",\"88d9857e584e\",\"9dc80918cc93\",\"8a9336e5bb4\",\"cef6983b292\",\"54c98c43354d\",\"193b68bd4fba\",\"b7e45b22fec3\",\"55760f21cdc5\"],\"tierOneDomains\":[\"medium.com\",\"thebolditalic.com\",\"arcdigital.media\",\"towardsdatascience.com\",\"uxdesign.cc\",\"codeburst.io\",\"psiloveyou.xyz\",\"writingcooperative.com\",\"entrepreneurshandbook.co\",\"prototypr.io\",\"betterhumans.coach.me\",\"theascent.pub\"],\"topicsToFollow\":[\"d61cf867d93f\",\"8a146bc21b28\",\"1eca0103fff3\",\"4d562ee63426\",\"aef1078a3ef5\",\"e15e46793f8d\",\"6158eb913466\",\"55f1c20aba7a\",\"3d18b94f6858\",\"4861fee224fd\",\"63c6f1f93ee\",\"1d98b3a9a871\",\"decb52b64abf\",\"ae5d4995e225\",\"830cded25262\"],\"defaultImages\":{\"avatar\":{\"imageId\":\"1*dmbNkD5D-u45r44go_cf0g.png\",\"height\":150,\"width\":150},\"orgLogo\":{\"imageId\":\"1*OMF3fSqH8t4xBJ9-6oZDZw.png\",\"height\":106,\"width\":545},\"postLogo\":{\"imageId\":\"1*kFrc4tBFM_tCis-2Ic87WA.png\",\"height\":810,\"width\":1440},\"postPreviewImage\":{\"imageId\":\"1*hn4v1tCaJy7cWMyb0bpNpQ.png\",\"height\":386,\"width\":579}},\"performanceTags\":[],\"collectionStructuredData\":{\"8d6b8a439e32\":{\"name\":\"Elemental\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fcdn-images-1.medium.com\\\\u002Fmax\\\\u002F980\\\\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png\",\"width\":980,\"height\":159}}},\"3f6ecf56618\":{\"name\":\"Forge\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fcdn-images-1.medium.com\\\\u002Fmax\\\\u002F596\\\\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png\",\"width\":596,\"height\":183}}},\"ae2a65f35510\":{\"name\":\"GEN\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F264\\\\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png\",\"width\":264,\"height\":140}}},\"88d9857e584e\":{\"name\":\"LEVEL\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F540\\\\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png\",\"width\":540,\"height\":108}}},\"7b6769f2748b\":{\"name\":\"Marker\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fcdn-images-1.medium.com\\\\u002Fmax\\\\u002F383\\\\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png\",\"width\":383,\"height\":92}}},\"444d13b52878\":{\"name\":\"OneZero\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F540\\\\u002F1*cw32fIqCbRWzwJaoQw6BUg.png\",\"width\":540,\"height\":123}}},\"8ccfed20cbb2\":{\"name\":\"Zora\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Farticles\\\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\\u002F\\\\u002Fmiro.medium.com\\\\u002Fmax\\\\u002F540\\\\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png\",\"width\":540,\"height\":106}}}},\"embeddedPostIds\":{\"coronavirus\":\"cd3010f9d81f\"},\"sharedCdcMessaging\":{\"COVID_APPLICABLE_TAG_SLUGS\":[],\"COVID_APPLICABLE_TOPIC_NAMES\":[],\"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE\":[],\"COVID_MESSAGES\":{\"tierA\":{\"text\":\"For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":66,\"end\":73,\"href\":\"https:\\\\u002F\\\\u002Fwww.cdc.gov\\\\u002Fcoronavirus\\\\u002F2019-nCoV\"}]},\"tierB\":{\"text\":\"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.\",\"markups\":[{\"start\":37,\"end\":45,\"href\":\"https:\\\\u002F\\\\u002Fhelp.medium.com\\\\u002Fhc\\\\u002Fen-us\\\\u002Fcategories\\\\u002F201931128-Policies-Safety\"},{\"start\":125,\"end\":132,\"href\":\"https:\\\\u002F\\\\u002Fwww.cdc.gov\\\\u002Fcoronavirus\\\\u002F2019-nCoV\"}]},\"paywall\":{\"text\":\"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":56,\"end\":70,\"href\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fmembership\"},{\"start\":138,\"end\":145,\"href\":\"https:\\\\u002F\\\\u002Fwww.cdc.gov\\\\u002Fcoronavirus\\\\u002F2019-nCoV\"}]},\"unbound\":{\"text\":\"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":45,\"end\":59,\"href\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fmembership\"},{\"start\":127,\"end\":134,\"href\":\"https:\\\\u002F\\\\u002Fwww.cdc.gov\\\\u002Fcoronavirus\\\\u002F2019-nCoV\"}]}},\"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST\":[\"3b31a67bff4a\"]},\"sharedVoteMessaging\":{\"TAGS\":[\"politics\",\"election-2020\",\"government\",\"us-politics\",\"election\",\"2020-presidential-race\",\"trump\",\"donald-trump\",\"democrats\",\"republicans\",\"congress\",\"republican-party\",\"democratic-party\",\"biden\",\"joe-biden\",\"maga\"],\"TOPICS\":[\"politics\",\"election\"],\"MESSAGE\":{\"text\":\"Find out more about the U.S. election results here.\",\"markups\":[{\"start\":46,\"end\":50,\"href\":\"https:\\\\u002F\\\\u002Fcookpolitical.com\\\\u002F2020-national-popular-vote-tracker\"}]},\"EXCLUDE_POSTS\":[\"397ef29e3ca5\"]},\"embedPostRules\":[],\"recircOptions\":{\"v1\":{\"limit\":3},\"v2\":{\"limit\":8}},\"braintreeClientKey\":\"production_zjkj96jm_m56f8fqpf7ngnrd4\",\"paypalClientId\":\"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v\",\"stripePublishableKey\":\"pk_live_7FReX44VnNIInZwrIIx6ghjl\",\"errorTracking\":\"none\"},\"debug\":{\"requestId\":\"1c915822-8ab8-4fb0-9751-bed55bedb5ac\",\"branchDeployConfig\":null,\"originalSpanCarrier\":{\"ot-tracer-spanid\":\"4a5d738a48ddc1bb\",\"ot-tracer-traceid\":\"7bb8570f02c9fee4\",\"ot-tracer-sampled\":\"true\"}},\"multiVote\":{\"clapsPerPost\":{}},\"navigation\":{\"branch\":{\"show\":null,\"hasRendered\":null,\"blockedByCTA\":false},\"hideGoogleOneTap\":false,\"hasRenderedGoogleOneTap\":null,\"hasRenderedAlternateUserBanner\":null,\"currentLocation\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fautomatic-image-captioning-using-deep-learning-5e899c127387\",\"host\":\"medium.com\",\"hostname\":\"medium.com\",\"susiModal\":{\"step\":null,\"operation\":\"register\"},\"postRead\":false},\"session\":{\"user\":{\"id\":\"lo_2707c6cfeb85\"},\"xsrf\":\"\",\"isSpoofed\":false},\"tracing\":{}}</script><script>window.__APOLLO_STATE__ = {\"ROOT_QUERY\":{\"__typename\":\"Query\",\"viewer\":null,\"variantFlags\":[{\"__typename\":\"VariantFlag\",\"name\":\"allow_access\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"allow_signup\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"allow_test_auth\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"disallow\"}},{\"__typename\":\"VariantFlag\",\"name\":\"android_enable_lock_responses\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"assign_default_topic_to_posts\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"available_annual_plan\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"2c754bcc2995\"}},{\"__typename\":\"VariantFlag\",\"name\":\"available_monthly_plan\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"60e220181034\"}},{\"__typename\":\"VariantFlag\",\"name\":\"bane_add_user\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"bane_verify_domain\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"branch_seo_metadata\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"browsable_stream_config_bucket\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"curated-topics\"}},{\"__typename\":\"VariantFlag\",\"name\":\"coronavirus_topic_recirc\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"covid_19_cdc_banner\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"default_seo_post_titles\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"disable_android_subscription_activity_carousel\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"disable_ios_resume_reading_toast\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"disable_ios_subscription_activity_carousel\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"disable_mobile_featured_chunk\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"disable_post_recommended_from_friends_provider\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_android_local_currency\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_annual_renewal_reminder_email\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_app_flirty_thirty\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_apple_parse_expires_at\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_apple_sign_in\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_apple_webhook\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_apple_webhook_renewal_failure\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_about_page_routing\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_general_admission\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_nav\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_profile_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_pub_follower_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_recirc\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_sticky_nav\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_aurora_tag_page_routing\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_author_autotier\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_author_cards\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_automated_mission_control_triggers\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_apple_pay\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_client\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_integration\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_paypal\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_trial_membership\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_braintree_webhook\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_branch_io\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_branch_text_me_the_app\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_branding\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_branding_fonts\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_cleansweep_double_writes\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_client_error_tracking\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"none\"}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_confirm_sign_in\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_cta_meter\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_curation_priority_queue_experiment\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_custom_domain_v2_settings\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_dedicated_series_tab_api_ios\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_digest_feature_logging\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_digest_tagline\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_earn_redirect\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_edit_alt_text\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_email_sign_in_captcha\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_email_to_subscribers_after_publish\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_embedding_based_diversification\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_end_of_post_cleanup\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_evhead_com_to_ev_medium_com_redirect\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_expanded_feature_chunk_pool\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_filter_by_resend_rules\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_filter_expire_processor\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_footer_app_buttons\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_fyf_authors_and_collections\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_global_susi_modal\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_google_one_tap\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_google_webhook\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_google_webhook_subscription_cancelled\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_highlander_member_digest\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_hightower_user_minimum_guarantee\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_homepage_who_to_follow_module\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_homepage_write_button\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_increased_digest_timeout\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_ios_post_stats\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_json_logs_trained_ranker\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_kbfd_rex\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_kbfd_rex_app_highlights\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_kbfd_rex_daily_digest\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_homepage\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_homepage_feed\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_notifications\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_pay_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_post\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_post_cd\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_pub_homepage_for_selected_domains\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_publish_to_profile\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_server_upstream_deadlines\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_stories\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_threaded_responses\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_topics\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lite_unread_notification_count_mutation\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_lock_responses\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_login_code_flow\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_marketing_emails\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_media_resource_try_catch\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_medium2_kbfd\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_membership_remove_section_a\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_miro_on_kubernetes\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_mission_control\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_ml_rank_modules\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_ml_rank_rex_anno\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_mute\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_new_checkout_flow\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_new_collaborative_filtering_data\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_new_login_flow\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_new_three_dot_menu\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_parsely\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_patronus_on_kubernetes\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_popularity_feature\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_post_import\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_post_page_nav_stickiness_removal\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_post_settings_screen\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_primary_topic_for_mobile\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_profile_design_reminder\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_profile_page_seo_titles\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_publish_to_email_for_publication_posts\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_receipt_notes\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_responses_2\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_responses_all\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_responses_edit_and_delete\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_responses_moderation\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_rex_follow_feed_cache\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_rito_upstream_deadlines\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_rtr_channel\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_s3_sites\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_save_to_medium\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_signup_friction\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_starspace\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_starspace_ranker_starspace\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_tick_landing_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_tipalti_onboarding\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_trending_posts_diversification\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_tribute_landing_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_triton_predictions\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_trumpland_landing_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_twitter_auth_suggestions\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_unfiltered_cf\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"enable_untruncated_author_post_as_email\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"glyph_font_set\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"m2-unbound\"}},{\"__typename\":\"VariantFlag\",\"name\":\"google_sign_in_android\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_enable_generic_home_modules\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_enable_home_post_menu\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_enable_iceland_paywall\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_enable_lock_responses\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_iceland_nux\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"ios_pub_follow_email_opt_in\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"is_not_medium_subscriber\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"kill_fastrak\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"kill_stripe_express\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"limit_post_referrers\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"limit_user_follows\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"make_nav_sticky\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"new_transition_page\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"provider_for_credit_card_form\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"BRAINTREE\"}},{\"__typename\":\"VariantFlag\",\"name\":\"pub_sidebar\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"redefine_average_post_reading_time\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"remove_post_post_similarity\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"retrained_ranker\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"sign_up_with_email_button\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"signin_services\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"twitter,facebook,google,email,google-fastidv,google-one-tap,apple\"}},{\"__typename\":\"VariantFlag\",\"name\":\"signup_services\",\"valueType\":{\"__typename\":\"VariantFlagString\",\"value\":\"twitter,facebook,google,email,google-fastidv,google-one-tap,apple\"}},{\"__typename\":\"VariantFlag\",\"name\":\"skip_sign_in_recaptcha\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"suppress_apple_missing_expires_date_alert\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}},{\"__typename\":\"VariantFlag\",\"name\":\"use_new_admin_topic_backend\",\"valueType\":{\"__typename\":\"VariantFlagBoolean\",\"value\":true}}],\"meterPost({\\\\\"postId\\\\\":\\\\\"5e899c127387\\\\\",\\\\\"postMeteringOptions\\\\\":{}})\":{\"__ref\":\"MeteringInfo:{}\"},\"postResult({\\\\\"id\\\\\":\\\\\"5e899c127387\\\\\"})\":{\"__ref\":\"Post:5e899c127387\"}},\"MeteringInfo:{}\":{\"__typename\":\"MeteringInfo\",\"postIds\":[],\"maxUnlockCount\":3,\"unlocksRemaining\":3},\"ImageMetadata:\":{\"id\":\"\",\"__typename\":\"ImageMetadata\"},\"ImageMetadata:1*IOJrKVmLnRcFz3E_KrrN_Q.png\":{\"id\":\"1*IOJrKVmLnRcFz3E_KrrN_Q.png\",\"__typename\":\"ImageMetadata\",\"originalWidth\":607,\"originalHeight\":104},\"User:d43c46db5b92\":{\"id\":\"d43c46db5b92\",\"__typename\":\"User\",\"name\":\"Ali Mese\"},\"ImageMetadata:1*Xd2uZaVHfrGOP14W_3UQRg.jpeg\":{\"id\":\"1*Xd2uZaVHfrGOP14W_3UQRg.jpeg\",\"__typename\":\"ImageMetadata\"},\"NewsletterV3:13df37cfc4c2\":{\"id\":\"13df37cfc4c2\",\"__typename\":\"NewsletterV3\",\"slug\":\"top-stories\",\"isSubscribed\":false,\"showPromo\":false,\"name\":\"Top Stories\",\"description\":\"The Startup\\'s best stories delivered straight into your inbox, once a month.\",\"type\":\"NEWSLETTER_TYPE_COLLECTION\",\"user\":{\"__ref\":\"User:d43c46db5b92\"},\"collection\":{\"__ref\":\"Collection:f5af2b715248\"}},\"Collection:f5af2b715248\":{\"id\":\"f5af2b715248\",\"__typename\":\"Collection\",\"domain\":null,\"googleAnalyticsId\":null,\"slug\":\"swlh\",\"colorBehavior\":\"ACCENT_COLOR_AND_FILL_BACKGROUND\",\"isAuroraVisible\":false,\"favicon\":{\"__ref\":\"ImageMetadata:\"},\"name\":\"The Startup\",\"colorPalette\":{\"__typename\":\"ColorPalette\",\"highlightSpectrum\":{\"__typename\":\"ColorSpectrum\",\"backgroundColor\":\"#FFFFFFFF\",\"colorPoints\":[{\"__typename\":\"ColorPoint\",\"color\":\"#FFF4F2F2\",\"point\":0},{\"__typename\":\"ColorPoint\",\"color\":\"#FFF2F0F0\",\"point\":0.1},{\"__typename\":\"ColorPoint\",\"color\":\"#FFF0EEEE\",\"point\":0.2},{\"__typename\":\"ColorPoint\",\"color\":\"#FFEEECEC\",\"point\":0.3},{\"__typename\":\"ColorPoint\",\"color\":\"#FFECEBEA\",\"point\":0.4},{\"__typename\":\"ColorPoint\",\"color\":\"#FFEAE9E8\",\"point\":0.5},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE8E7E7\",\"point\":0.6},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE6E5E5\",\"point\":0.7},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE4E3E3\",\"point\":0.8},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE2E1E1\",\"point\":0.9},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE0DFDF\",\"point\":1}]},\"defaultBackgroundSpectrum\":{\"__typename\":\"ColorSpectrum\",\"backgroundColor\":\"#FFFFFFFF\",\"colorPoints\":[{\"__typename\":\"ColorPoint\",\"color\":\"#FF848585\",\"point\":0},{\"__typename\":\"ColorPoint\",\"color\":\"#FF7B7B7B\",\"point\":0.1},{\"__typename\":\"ColorPoint\",\"color\":\"#FF717272\",\"point\":0.2},{\"__typename\":\"ColorPoint\",\"color\":\"#FF686868\",\"point\":0.3},{\"__typename\":\"ColorPoint\",\"color\":\"#FF5E5E5E\",\"point\":0.4},{\"__typename\":\"ColorPoint\",\"color\":\"#FF545454\",\"point\":0.5},{\"__typename\":\"ColorPoint\",\"color\":\"#FF494A4A\",\"point\":0.6},{\"__typename\":\"ColorPoint\",\"color\":\"#FF3F3F3F\",\"point\":0.7},{\"__typename\":\"ColorPoint\",\"color\":\"#FF333333\",\"point\":0.8},{\"__typename\":\"ColorPoint\",\"color\":\"#FF272727\",\"point\":0.9},{\"__typename\":\"ColorPoint\",\"color\":\"#FF1A1A1A\",\"point\":1}]},\"tintBackgroundSpectrum\":{\"__typename\":\"ColorSpectrum\",\"backgroundColor\":\"#FFF9F9F9\",\"colorPoints\":[{\"__typename\":\"ColorPoint\",\"color\":\"#FFF9F9F9\",\"point\":0},{\"__typename\":\"ColorPoint\",\"color\":\"#FFE7E7E7\",\"point\":0.1},{\"__typename\":\"ColorPoint\",\"color\":\"#FFD4D4D4\",\"point\":0.2},{\"__typename\":\"ColorPoint\",\"color\":\"#FFC1C1C1\",\"point\":0.3},{\"__typename\":\"ColorPoint\",\"color\":\"#FFADADAE\",\"point\":0.4},{\"__typename\":\"ColorPoint\",\"color\":\"#FF989999\",\"point\":0.5},{\"__typename\":\"ColorPoint\",\"color\":\"#FF838484\",\"point\":0.6},{\"__typename\":\"ColorPoint\",\"color\":\"#FF6D6E6E\",\"point\":0.7},{\"__typename\":\"ColorPoint\",\"color\":\"#FF565757\",\"point\":0.8},{\"__typename\":\"ColorPoint\",\"color\":\"#FF3C3E3E\",\"point\":0.9},{\"__typename\":\"ColorPoint\",\"color\":\"#FF202122\",\"point\":1}]}},\"customStyleSheet\":null,\"tagline\":\"Medium\\'s largest active publication, followed by +768K people. Follow to join our community.\",\"isAuroraEligible\":true,\"viewerIsEditor\":false,\"logo\":{\"__ref\":\"ImageMetadata:1*IOJrKVmLnRcFz3E_KrrN_Q.png\"},\"navItems\":[{\"__typename\":\"NavItem\",\"title\":\"Submit\",\"url\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fwhen-one-upvote-is-worth-a-thousand-visitors-3e8ed27bcd3e\",\"type\":\"POST_NAV_ITEM\"},{\"__typename\":\"NavItem\",\"title\":\"Get smarter at writing\",\"url\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fblankpage\",\"type\":\"EXTERNAL_LINK_NAV_ITEM\"}],\"creator\":{\"__ref\":\"User:d43c46db5b92\"},\"subscriberCount\":769870,\"avatar\":{\"__ref\":\"ImageMetadata:1*Xd2uZaVHfrGOP14W_3UQRg.jpeg\"},\"isEnrolledInHightower\":false,\"newsletterV3\":{\"__ref\":\"NewsletterV3:13df37cfc4c2\"},\"viewerIsFollowing\":false,\"viewerIsSubscribedToLetters\":false,\"canToggleEmail\":true,\"isUserSubscribedToCollectionEmails\":false,\"viewerIsMuting\":false,\"viewerCanEditOwnPosts\":false,\"viewerCanEditPosts\":false,\"description\":\"Medium\\'s largest active publication, followed by +768K people. Follow to join our community.\",\"ampEnabled\":false,\"twitterUsername\":\"thestartup_\",\"facebookPageId\":null},\"User:470b7c52ceb\":{\"id\":\"470b7c52ceb\",\"__typename\":\"User\",\"isFollowing\":null,\"viewerIsUser\":false,\"isSuspended\":false,\"name\":\"Manthan Bhikadiya\",\"hasCompletedProfile\":false,\"bio\":\"\",\"imageId\":\"1*HJ2c7fuPyJGJzb9Hi4veog.jpeg\",\"customStyleSheet\":null,\"customDomainState\":null,\"username\":\"manthan.bhikadiya\",\"isAuroraVisible\":true,\"socialStats\":{\"__typename\":\"SocialStats\",\"followerCount\":4},\"isBlocking\":null,\"mediumMemberAt\":0,\"hasSubdomain\":false,\"isMuting\":null,\"allowNotes\":true,\"newsletterV3\":null,\"twitterScreenName\":\"\",\"isPartnerProgramEnrolled\":false},\"Topic:1eca0103fff3\":{\"id\":\"1eca0103fff3\",\"__typename\":\"Topic\",\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"isFollowing\":null},\"Paragraph:c9b2ede9f51e_0\":{\"id\":\"c9b2ede9f51e_0\",\"__typename\":\"Paragraph\",\"name\":\"44f7\",\"text\":\"Automatic Image Captioning Using Deep Learning\",\"type\":\"H3\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_1\":{\"id\":\"c9b2ede9f51e_1\",\"__typename\":\"Paragraph\",\"name\":\"f966\",\"text\":\"Overview of Deep Learning:\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":26,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_2\":{\"id\":\"c9b2ede9f51e_2\",\"__typename\":\"Paragraph\",\"name\":\"7539\",\"text\":\"Deep learning and Machine learning are the most progressive technologies in this era. Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans. Day by day there is new research in this field. This field is increasing very fast because now we have sufficient computational power for doing this task. Deep learning is a branch of machine learning that uses neural networks with many layers.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_3\":{\"id\":\"c9b2ede9f51e_3\",\"__typename\":\"Paragraph\",\"name\":\"d64f\",\"text\":\"In traditional machine learning, the algorithm is given a set of relevant features to analyze. However, in deep learning, the algorithm is given raw data and decides for itself what features are relevant. Deep learning networks will often improve as you increase the amount of data being used to train them.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":307,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":307,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_4\":{\"id\":\"c9b2ede9f51e_4\",\"__typename\":\"Paragraph\",\"name\":\"f686\",\"text\":\"Read More About Simple Explanation of Deep Learning here\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":52,\"end\":56,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fenterprisersproject.com\\\\u002Farticle\\\\u002F2019\\\\u002F7\\\\u002Fdeep-learning-explained-plain-english#:~:text=%E2%80%9CDeep%20learning%20is%20a%20branch%20of%20machine%20learning%20that,neural%20networks%20with%20many%20layers.&text=However%2C%20in%20deep%20learning%2C%20the,being%20used%20to%20train%20them.%E2%80%9D\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_5\":{\"id\":\"c9b2ede9f51e_5\",\"__typename\":\"Paragraph\",\"name\":\"625e\",\"text\":\"There Are some very interesting deep learning applications shown below.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_6\":{\"id\":\"c9b2ede9f51e_6\",\"__typename\":\"Paragraph\",\"name\":\"c861\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*e4MaH6-Th0pYEPAr.jpg\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_7\":{\"id\":\"c9b2ede9f51e_7\",\"__typename\":\"Paragraph\",\"name\":\"9be0\",\"text\":\"Source:-https:\\\\u002F\\\\u002Ftechvidvan.com\\\\u002Ftutorials\\\\u002Fdeep-learning-applications\\\\u002F\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":8,\"end\":68,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Ftechvidvan.com\\\\u002Ftutorials\\\\u002Fdeep-learning-applications\\\\u002F\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_8\":{\"id\":\"c9b2ede9f51e_8\",\"__typename\":\"Paragraph\",\"name\":\"0501\",\"text\":\"Now We will be going to see one of its applications which is Photo descriptions or image captions generator.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_9\":{\"id\":\"c9b2ede9f51e_9\",\"__typename\":\"Paragraph\",\"name\":\"467c\",\"text\":\"Image Captions Generator :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":26,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_10\":{\"id\":\"c9b2ede9f51e_10\",\"__typename\":\"Paragraph\",\"name\":\"05a5\",\"text\":\"Image Caption Generator or Photo Descriptions is one of the Applications of Deep Learning. In Which we have to pass the image to the model and the model does some processing and generating captions or descriptions as per its training. This prediction is sometimes not that much accurate and generates some meaningless sentences. We need very high computational power and a very huge dataset for better results. Now we will see some information about the dataset and the architecture of the neural network of the Image captions generator.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_11\":{\"id\":\"c9b2ede9f51e_11\",\"__typename\":\"Paragraph\",\"name\":\"8047\",\"text\":\"Pre-requisites :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":16,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_12\":{\"id\":\"c9b2ede9f51e_12\",\"__typename\":\"Paragraph\",\"name\":\"4ef9\",\"text\":\"This project requires good knowledge of Deep learning, Python, working on Jupyter notebooks, Keras library, Numpy, and Natural language Processing\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":119,\"end\":146,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_13\":{\"id\":\"c9b2ede9f51e_13\",\"__typename\":\"Paragraph\",\"name\":\"1f59\",\"text\":\"Make sure you have installed all the following necessary libraries:\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_14\":{\"id\":\"c9b2ede9f51e_14\",\"__typename\":\"Paragraph\",\"name\":\"8929\",\"text\":\"Tensorflow\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_15\":{\"id\":\"c9b2ede9f51e_15\",\"__typename\":\"Paragraph\",\"name\":\"ced5\",\"text\":\"Keras\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_16\":{\"id\":\"c9b2ede9f51e_16\",\"__typename\":\"Paragraph\",\"name\":\"bd72\",\"text\":\"Pandas\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_17\":{\"id\":\"c9b2ede9f51e_17\",\"__typename\":\"Paragraph\",\"name\":\"afee\",\"text\":\"NumPy\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_18\":{\"id\":\"c9b2ede9f51e_18\",\"__typename\":\"Paragraph\",\"name\":\"531d\",\"text\":\"nltk ( Natural language tool kit)\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_19\":{\"id\":\"c9b2ede9f51e_19\",\"__typename\":\"Paragraph\",\"name\":\"fcfd\",\"text\":\"Jupyter- IDE\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_20\":{\"id\":\"c9b2ede9f51e_20\",\"__typename\":\"Paragraph\",\"name\":\"0c5a\",\"text\":\"Dataset :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":9,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_21\":{\"id\":\"c9b2ede9f51e_21\",\"__typename\":\"Paragraph\",\"name\":\"f62e\",\"text\":\"In this project, we are using the flicker 30k dataset. In which it has 30,000 images with image id and a particular id has 5 captions generated.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_22\":{\"id\":\"c9b2ede9f51e_22\",\"__typename\":\"Paragraph\",\"name\":\"ebf5\",\"text\":\"Here is the link to the dataset so that you can also download that dataset.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_23\":{\"id\":\"c9b2ede9f51e_23\",\"__typename\":\"Paragraph\",\"name\":\"81ba\",\"text\":\"Flicker_30k:- https:\\\\u002F\\\\u002Fwww.kaggle.com\\\\u002Fhsankesara\\\\u002Fflickr-image-dataset\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":14,\"end\":68,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fwww.kaggle.com\\\\u002Fhsankesara\\\\u002Fflickr-image-dataset\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_24\":{\"id\":\"c9b2ede9f51e_24\",\"__typename\":\"Paragraph\",\"name\":\"032b\",\"text\":\"One of the Image in Dataset with ID 1000092795\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_25\":{\"id\":\"c9b2ede9f51e_25\",\"__typename\":\"Paragraph\",\"name\":\"fdd2\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*VDg65RlgojBJb8dl.jpg\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_26\":{\"id\":\"c9b2ede9f51e_26\",\"__typename\":\"Paragraph\",\"name\":\"ec6b\",\"text\":\"1000092795.jpg\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_27\":{\"id\":\"c9b2ede9f51e_27\",\"__typename\":\"Paragraph\",\"name\":\"837e\",\"text\":\"Here are the particular captions for these images which is present in the dataset.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_28\":{\"id\":\"c9b2ede9f51e_28\",\"__typename\":\"Paragraph\",\"name\":\"cbe2\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*T7NnEfDUrl6y90BV.JPG\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_29\":{\"id\":\"c9b2ede9f51e_29\",\"__typename\":\"Paragraph\",\"name\":\"f48f\",\"text\":\"The Architecture of Network :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":29,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_30\":{\"id\":\"c9b2ede9f51e_30\",\"__typename\":\"Paragraph\",\"name\":\"ec00\",\"text\":\"1 .Image Features Detection :\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":29,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":29,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_31\":{\"id\":\"c9b2ede9f51e_31\",\"__typename\":\"Paragraph\",\"name\":\"1df4\",\"text\":\"For image Detecting, we are using a pre-trained model which is VGG16. VGG16 is already installed in the Keras library.VGG 16 was proposed by Karen Simonyan and Andrew Zisserman of the Visual Geometry Group Lab of Oxford University in 2014 in the paper VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":252,\"end\":319,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fneurohive.io\\\\u002Fen\\\\u002Fpopular-networks\\\\u002Fvgg16\\\\u002F\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_32\":{\"id\":\"c9b2ede9f51e_32\",\"__typename\":\"Paragraph\",\"name\":\"9bb1\",\"text\":\"This model won the ILSVRC challenge in 2014.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_33\":{\"id\":\"c9b2ede9f51e_33\",\"__typename\":\"Paragraph\",\"name\":\"b1af\",\"text\":\"Here is the model representation in 3-D and in 2-D.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_34\":{\"id\":\"c9b2ede9f51e_34\",\"__typename\":\"Paragraph\",\"name\":\"585b\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*-vdH52g5TwhLPm26.JPG\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_35\":{\"id\":\"c9b2ede9f51e_35\",\"__typename\":\"Paragraph\",\"name\":\"239b\",\"text\":\"Source:-Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":8,\"end\":74,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fneurohive.io\\\\u002Fen\\\\u002Fpopular-networks\\\\u002Fvgg16\\\\u002F\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_36\":{\"id\":\"c9b2ede9f51e_36\",\"__typename\":\"Paragraph\",\"name\":\"fbae\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*vuoNCrq7R_s7WCEK.JPG\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_37\":{\"id\":\"c9b2ede9f51e_37\",\"__typename\":\"Paragraph\",\"name\":\"26f4\",\"text\":\"Source:-VGG16 | CNN Model GFG\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":28,\"end\":29,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":28,\"end\":29,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_38\":{\"id\":\"c9b2ede9f51e_38\",\"__typename\":\"Paragraph\",\"name\":\"043a\",\"text\":\"Overview :\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":10,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":10,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_39\":{\"id\":\"c9b2ede9f51e_39\",\"__typename\":\"Paragraph\",\"name\":\"70c2\",\"text\":\"The input to conv1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left\\\\u002Fright, up\\\\u002Fdown, center). In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3×3 conv. layers. Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2×2 pixel window, with stride 2.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_40\":{\"id\":\"c9b2ede9f51e_40\",\"__typename\":\"Paragraph\",\"name\":\"038f\",\"text\":\"Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_41\":{\"id\":\"c9b2ede9f51e_41\",\"__typename\":\"Paragraph\",\"name\":\"4baa\",\"text\":\"Read More Here\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":10,\"end\":14,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fcolah.github.io\\\\u002Fposts\\\\u002F2015-08-Understanding-LSTMs\\\\u002F\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_42\":{\"id\":\"c9b2ede9f51e_42\",\"__typename\":\"Paragraph\",\"name\":\"3c83\",\"text\":\"2. Text Generation using LSTM\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":29,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":29,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_43\":{\"id\":\"c9b2ede9f51e_43\",\"__typename\":\"Paragraph\",\"name\":\"3c34\",\"text\":\"Long Short Term Memory networks — usually just called “LSTMs” — are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997) and were refined and popularized by many people in the following work. They work tremendously well on a large variety of problems and are now widely used.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":159,\"end\":190,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fwww.blogger.com\\\\u002Fu\\\\u002F1\\\\u002Fblog\\\\u002Fpost\\\\u002Fedit\\\\u002F5255967751950062393\\\\u002F3581114184014589371#\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_44\":{\"id\":\"c9b2ede9f51e_44\",\"__typename\":\"Paragraph\",\"name\":\"e907\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*9ITR9tOQlCSyWmKH.JPG\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_45\":{\"id\":\"c9b2ede9f51e_45\",\"__typename\":\"Paragraph\",\"name\":\"80af\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:1*kp29KmqfPXMdCckPAb4I3Q.jpeg\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_46\":{\"id\":\"c9b2ede9f51e_46\",\"__typename\":\"Paragraph\",\"name\":\"21d1\",\"text\":\"Source:-LSTM Networks\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":8,\"end\":21,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fcolah.github.io\\\\u002Fposts\\\\u002F2015-08-Understanding-LSTMs\\\\u002F\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_47\":{\"id\":\"c9b2ede9f51e_47\",\"__typename\":\"Paragraph\",\"name\":\"4ba3\",\"text\":\"Overview :\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":10,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":10,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_48\":{\"id\":\"c9b2ede9f51e_48\",\"__typename\":\"Paragraph\",\"name\":\"56d6\",\"text\":\"A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":36,\"end\":40,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":45,\"end\":55,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":60,\"end\":71,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":78,\"end\":89,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":161,\"end\":166,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_49\":{\"id\":\"c9b2ede9f51e_49\",\"__typename\":\"Paragraph\",\"name\":\"2279\",\"text\":\"LSTM networks are well-suited to classifying, processing, and making predictions based on time series data since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models, and other sequence learning methods in numerous applications.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_50\":{\"id\":\"c9b2ede9f51e_50\",\"__typename\":\"Paragraph\",\"name\":\"cf56\",\"text\":\"The advantage of an LSTM cell compared to a common recurrent unit is its cell memory unit. The cell vector has the ability to encapsulate the notion of forgetting part of its previously-stored memory, as well as to add part of the new information. To illustrate this, one has to inspect the equations of the cell and the way it processes sequences under the hood.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_51\":{\"id\":\"c9b2ede9f51e_51\",\"__typename\":\"Paragraph\",\"name\":\"7a96\",\"text\":\"Now we are combining this model architecture in one model and that is our final model which will generate caption from images.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_52\":{\"id\":\"c9b2ede9f51e_52\",\"__typename\":\"Paragraph\",\"name\":\"6d0d\",\"text\":\"Read Wikipedia:-LSTM Networks Full explained\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":16,\"end\":44,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fen.wikipedia.org\\\\u002Fwiki\\\\u002FLong_short-term_memory\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_53\":{\"id\":\"c9b2ede9f51e_53\",\"__typename\":\"Paragraph\",\"name\":\"a714\",\"text\":\"Main Model Architecture:\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":24,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_54\":{\"id\":\"c9b2ede9f51e_54\",\"__typename\":\"Paragraph\",\"name\":\"faf7\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*ENpcH_oTsR4CNlNg.png\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_55\":{\"id\":\"c9b2ede9f51e_55\",\"__typename\":\"Paragraph\",\"name\":\"ad61\",\"text\":\"This final model is a combination of CNN and RNN models. To train this model we have to give two inputs two the models. (1) Images (2) Corresponding Captions. For each LSTM layer, we input one word for each LSTM layer, and each LSTM layer predicts the next word, and that how the LSTM model optimizes itself by learning from captions. For Image features, we are getting All image features array from the VGG16 pre-trained model and saved in a file so that we can use this file or features directly to correlate captions and image features with each other. Finally the image features and LSTM last layer we input this both outputs combination into decoder model in which we are adding both image features and captions so that model learns to generate captions from images and for a final layer we generate output or captions which length is the maximum length of dataset captions.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_56\":{\"id\":\"c9b2ede9f51e_56\",\"__typename\":\"Paragraph\",\"name\":\"7fa2\",\"text\":\"The last layer has a size of the length of the vocab. For this model, we are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words. We are using Adam optimizer for optimization of the network or update the weights of the network.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_57\":{\"id\":\"c9b2ede9f51e_57\",\"__typename\":\"Paragraph\",\"name\":\"6922\",\"text\":\"Bleu Score :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":12,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":12,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_58\":{\"id\":\"c9b2ede9f51e_58\",\"__typename\":\"Paragraph\",\"name\":\"0af7\",\"text\":\"We can generate captions with the n-grams model for that purpose we are using Blue-score for this model. By using BLEU Score we can check which n-gram is best to generate captions for this dataset.BLEU Score lies between 0 and 1. BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of the text to one or more reference translations. Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":243,\"end\":274,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_59\":{\"id\":\"c9b2ede9f51e_59\",\"__typename\":\"Paragraph\",\"name\":\"9605\",\"text\":\"Model Summary :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":15,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_60\":{\"id\":\"c9b2ede9f51e_60\",\"__typename\":\"Paragraph\",\"name\":\"bea3\",\"text\":\"\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:0*LVF9PPW57DSPZ_lf.JPG\"},\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_61\":{\"id\":\"c9b2ede9f51e_61\",\"__typename\":\"Paragraph\",\"name\":\"b75f\",\"text\":\"Github:\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":7,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_62\":{\"id\":\"c9b2ede9f51e_62\",\"__typename\":\"Paragraph\",\"name\":\"a28f\",\"text\":\"manthan89-py\\\\u002FImage-Caption-Generator\\\\nFor this Projet you must have a complete understanding of CNN, LSTM and Transfer learning You can also check for my blog…github.com\",\"type\":\"MIXTAPE_EMBED\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":{\"__typename\":\"MixtapeMetadata\",\"href\":\"https:\\\\u002F\\\\u002Fgithub.com\\\\u002Fmanthan89-py\\\\u002FImage-Caption-Generator\",\"thumbnailImageId\":\"0*6NwyiP-i0fJlh4Bz\"},\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":168,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fgithub.com\\\\u002Fmanthan89-py\\\\u002FImage-Caption-Generator\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":0,\"end\":36,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null},{\"__typename\":\"Markup\",\"start\":37,\"end\":158,\"type\":\"EM\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_63\":{\"id\":\"c9b2ede9f51e_63\",\"__typename\":\"Paragraph\",\"name\":\"7ee2\",\"text\":\"Also, check out my other projects and if you find it useful then don’t forget to give a star.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_64\":{\"id\":\"c9b2ede9f51e_64\",\"__typename\":\"Paragraph\",\"name\":\"4ef2\",\"text\":\"Conclusion :\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":12,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_65\":{\"id\":\"c9b2ede9f51e_65\",\"__typename\":\"Paragraph\",\"name\":\"018a\",\"text\":\"Finally, conclude this project we understand VGG16 model Architecture, Long short term memory Network, how to combine this both model, bleu score, How the LSTM network generates captions, How the VGG16 model we can use for our project, and how to generate captions from images using deep learning.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_66\":{\"id\":\"c9b2ede9f51e_66\",\"__typename\":\"Paragraph\",\"name\":\"2e67\",\"text\":\"More Blogs On Image Captions:\",\"type\":\"BQ\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":28,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_67\":{\"id\":\"c9b2ede9f51e_67\",\"__typename\":\"Paragraph\",\"name\":\"588a\",\"text\":\"Image Captioning in Python with Keras\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":37,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fimage-captioning-in-python-with-keras-870f976e0f18\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_68\":{\"id\":\"c9b2ede9f51e_68\",\"__typename\":\"Paragraph\",\"name\":\"f837\",\"text\":\"Image Caption Using Attention Mechanism\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":39,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fimage-captioning-using-attention-mechanism-f3d7fc96eb0e\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_69\":{\"id\":\"c9b2ede9f51e_69\",\"__typename\":\"Paragraph\",\"name\":\"4450\",\"text\":\"Automatic Image Captioning With CNN and RNN\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":43,\"type\":\"A\",\"href\":\"https:\\\\u002F\\\\u002Ftowardsdatascience.com\\\\u002Fautomatic-image-captioning-with-cnn-rnn-aae3cd442d83\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"Paragraph:c9b2ede9f51e_70\":{\"id\":\"c9b2ede9f51e_70\",\"__typename\":\"Paragraph\",\"name\":\"70a9\",\"text\":\"Thanks for reading! If you enjoyed this article, please hit the clap button as many times as you can. It would mean a lot and encourage me to keep sharing my knowledge.\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"hasDropCap\":null,\"iframe\":null,\"mixtapeMetadata\":null,\"markups\":[{\"__typename\":\"Markup\",\"start\":0,\"end\":168,\"type\":\"STRONG\",\"href\":null,\"anchorType\":null,\"userId\":null,\"linkMetadata\":null}],\"dropCapImage\":null},\"ImageMetadata:0*e4MaH6-Th0pYEPAr.jpg\":{\"id\":\"0*e4MaH6-Th0pYEPAr.jpg\",\"__typename\":\"ImageMetadata\",\"originalHeight\":301,\"originalWidth\":574,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*VDg65RlgojBJb8dl.jpg\":{\"id\":\"0*VDg65RlgojBJb8dl.jpg\",\"__typename\":\"ImageMetadata\",\"originalHeight\":378,\"originalWidth\":252,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*T7NnEfDUrl6y90BV.JPG\":{\"id\":\"0*T7NnEfDUrl6y90BV.JPG\",\"__typename\":\"ImageMetadata\",\"originalHeight\":249,\"originalWidth\":620,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*-vdH52g5TwhLPm26.JPG\":{\"id\":\"0*-vdH52g5TwhLPm26.JPG\",\"__typename\":\"ImageMetadata\",\"originalHeight\":286,\"originalWidth\":541,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*vuoNCrq7R_s7WCEK.JPG\":{\"id\":\"0*vuoNCrq7R_s7WCEK.JPG\",\"__typename\":\"ImageMetadata\",\"originalHeight\":240,\"originalWidth\":565,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*9ITR9tOQlCSyWmKH.JPG\":{\"id\":\"0*9ITR9tOQlCSyWmKH.JPG\",\"__typename\":\"ImageMetadata\",\"originalHeight\":240,\"originalWidth\":615,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:1*kp29KmqfPXMdCckPAb4I3Q.jpeg\":{\"id\":\"1*kp29KmqfPXMdCckPAb4I3Q.jpeg\",\"__typename\":\"ImageMetadata\",\"originalHeight\":133,\"originalWidth\":730,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*ENpcH_oTsR4CNlNg.png\":{\"id\":\"0*ENpcH_oTsR4CNlNg.png\",\"__typename\":\"ImageMetadata\",\"originalHeight\":266,\"originalWidth\":564,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"ImageMetadata:0*LVF9PPW57DSPZ_lf.JPG\":{\"id\":\"0*LVF9PPW57DSPZ_lf.JPG\",\"__typename\":\"ImageMetadata\",\"originalHeight\":472,\"originalWidth\":603,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"Tag:image-captioning\":{\"id\":\"image-captioning\",\"__typename\":\"Tag\",\"displayTitle\":\"Image Captioning\"},\"Tag:machine-learning\":{\"id\":\"machine-learning\",\"__typename\":\"Tag\",\"displayTitle\":\"Machine Learning\"},\"Tag:deep-learning\":{\"id\":\"deep-learning\",\"__typename\":\"Tag\",\"displayTitle\":\"Deep Learning\"},\"Tag:computer-vision\":{\"id\":\"computer-vision\",\"__typename\":\"Tag\",\"displayTitle\":\"Computer Vision\"},\"Tag:naturallanguageprocessing\":{\"id\":\"naturallanguageprocessing\",\"__typename\":\"Tag\",\"displayTitle\":\"Naturallanguageprocessing\"},\"ImageMetadata:1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg\":{\"id\":\"1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"Collection:853867ec3a23\":{\"id\":\"853867ec3a23\",\"__typename\":\"Collection\",\"name\":\"data from the trenches\",\"slug\":\"data-from-the-trenches\",\"domain\":null},\"User:eca1e814baab\":{\"id\":\"eca1e814baab\",\"__typename\":\"User\",\"name\":\"Aimee Coelho\",\"username\":\"aimee.coelho_27638\",\"bio\":\"Research Scientist at Dataiku\",\"isFollowing\":null,\"imageId\":\"2*RengedPDtY6Hf9b7i6mzmA.png\",\"mediumMemberAt\":0,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:5e984ab760be\":{\"id\":\"5e984ab760be\",\"__typename\":\"Post\",\"title\":\"Narrowing the Search: Which Hyperparameters Really Matter?\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fdata-from-the-trenches\\\\u002Fnarrowing-the-search-which-hyperparameters-really-matter-5e984ab760be\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*9oS6zLrKhTl4Z0DZDMVU6Q.jpeg\"},\"isPublished\":true,\"firstPublishedAt\":1588858257612,\"readingTime\":7.520754716981132,\"statusForCollection\":\"APPROVED\",\"isLocked\":false,\"isShortform\":false,\"visibility\":\"PUBLIC\",\"collection\":{\"__ref\":\"Collection:853867ec3a23\"},\"creator\":{\"__ref\":\"User:eca1e814baab\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:1*gp1hjJ3ENY5SuKRljl62jg.jpeg\":{\"id\":\"1*gp1hjJ3ENY5SuKRljl62jg.jpeg\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"User:686b78ddcf4b\":{\"id\":\"686b78ddcf4b\",\"__typename\":\"User\",\"name\":\"Mate Pocs\",\"username\":\"matepocs\",\"bio\":\"Writing about Data Science.\",\"isFollowing\":null,\"imageId\":\"2*jXoCh-SVrqwYCgsTvGiL3g.jpeg\",\"mediumMemberAt\":1579008327000,\"customDomainState\":{\"__typename\":\"CustomDomainState\",\"live\":{\"__typename\":\"CustomDomain\",\"domain\":\"matepocs.medium.com\"}},\"hasSubdomain\":true},\"Post:5eabb6487b9b\":{\"id\":\"5eabb6487b9b\",\"__typename\":\"Post\",\"title\":\"Solutions for a Dice Game\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fsolutions-for-a-dice-game-5eabb6487b9b\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*gp1hjJ3ENY5SuKRljl62jg.jpeg\"},\"isPublished\":true,\"firstPublishedAt\":1581002415575,\"readingTime\":15.025471698113208,\"statusForCollection\":\"APPROVED\",\"isLocked\":true,\"isShortform\":false,\"visibility\":\"LOCKED\",\"collection\":{\"__ref\":\"Collection:f5af2b715248\"},\"creator\":{\"__ref\":\"User:686b78ddcf4b\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:1*egs26dtg9ilc8KfYxmp2dg.jpeg\":{\"id\":\"1*egs26dtg9ilc8KfYxmp2dg.jpeg\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"User:c8c2efaa555f\":{\"id\":\"c8c2efaa555f\",\"__typename\":\"User\",\"name\":\"Olivier Michaud\",\"username\":\"oliviermichaud_62658\",\"bio\":\"Software engineering student, master in artificial intelligence at École de technologie supérieure, Montréal, Canada. olivier.michaud.1@ens.etsmtl.ca\",\"isFollowing\":null,\"imageId\":\"1*MzduWzG32C8k-kpTozmKPQ.jpeg\",\"mediumMemberAt\":0,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:5e0deb70cd75\":{\"id\":\"5e0deb70cd75\",\"__typename\":\"Post\",\"title\":\"Star Wars: An NLP Adventure\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fstar-wars-an-nlp-adventure-5e0deb70cd75\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*egs26dtg9ilc8KfYxmp2dg.jpeg\"},\"isPublished\":true,\"firstPublishedAt\":1600705275573,\"readingTime\":4.533333333333333,\"statusForCollection\":\"APPROVED\",\"isLocked\":true,\"isShortform\":false,\"visibility\":\"LOCKED\",\"collection\":{\"__ref\":\"Collection:f5af2b715248\"},\"creator\":{\"__ref\":\"User:c8c2efaa555f\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:0*ZWEMdg-4KzYyCdWr\":{\"id\":\"0*ZWEMdg-4KzYyCdWr\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"Collection:283f7138fc2a\":{\"id\":\"283f7138fc2a\",\"__typename\":\"Collection\",\"name\":\"AI Graduate\",\"slug\":\"x8-the-ai-community\",\"domain\":null},\"User:552f4a4a68a2\":{\"id\":\"552f4a4a68a2\",\"__typename\":\"User\",\"name\":\"Prateek Karkare\",\"username\":\"prateekkarkare\",\"bio\":\"Observe.Learn.Repeat | Artificial Intelligence, Electronics, Music, Travel\",\"isFollowing\":null,\"imageId\":\"1*wTepRSOi6fIJpeLEHwhFAw.jpeg\",\"mediumMemberAt\":0,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:5e1480e6f52a\":{\"id\":\"5e1480e6f52a\",\"__typename\":\"Post\",\"title\":\"A 7 Minute Introduction to LSTM\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fx8-the-ai-community\\\\u002Fa-7-minute-introduction-to-lstm-5e1480e6f52a\",\"previewImage\":{\"__ref\":\"ImageMetadata:0*ZWEMdg-4KzYyCdWr\"},\"isPublished\":true,\"firstPublishedAt\":1574431261678,\"readingTime\":6.164150943396226,\"statusForCollection\":\"APPROVED\",\"isLocked\":true,\"isShortform\":false,\"visibility\":\"LOCKED\",\"collection\":{\"__ref\":\"Collection:283f7138fc2a\"},\"creator\":{\"__ref\":\"User:552f4a4a68a2\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg\":{\"id\":\"1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"Collection:32881626c9c9\":{\"id\":\"32881626c9c9\",\"__typename\":\"Collection\",\"name\":\"Data Driven Investor\",\"slug\":\"datadriveninvestor\",\"domain\":\"medium.datadriveninvestor.com\"},\"User:1f015e9ee21d\":{\"id\":\"1f015e9ee21d\",\"__typename\":\"User\",\"name\":\"Gianluca Malato\",\"username\":\"gianlucamalato\",\"bio\":\"Theoretical Physicists, Data Scientist and fiction author. I teach Data Science, statistics and SQL on YourDataTeacher.com\",\"isFollowing\":null,\"imageId\":\"0*hl6JPDu8FEzvORUS.\",\"mediumMemberAt\":0,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:5df55782b21b\":{\"id\":\"5df55782b21b\",\"__typename\":\"Post\",\"title\":\"Assessing the risk of a trading strategy using Monte Carlo analysis in R\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fdatadriveninvestor\\\\u002Fassessing-the-risk-of-a-trading-strategy-using-monte-carlo-analysis-in-r-5df55782b21b\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*ErgQ_NMwOCW1-kLQkiVqwg.jpeg\"},\"isPublished\":true,\"firstPublishedAt\":1547904906307,\"readingTime\":5.277358490566038,\"statusForCollection\":\"APPROVED\",\"isLocked\":true,\"isShortform\":false,\"visibility\":\"LOCKED\",\"collection\":{\"__ref\":\"Collection:32881626c9c9\"},\"creator\":{\"__ref\":\"User:1f015e9ee21d\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:1*N04OvC-wThS6M3rAfJ2VQA.jpeg\":{\"id\":\"1*N04OvC-wThS6M3rAfJ2VQA.jpeg\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"User:d19d33dbfacc\":{\"id\":\"d19d33dbfacc\",\"__typename\":\"User\",\"name\":\"Matthew Ellis\",\"username\":\"matthew.p.ellis23\",\"bio\":\"Interdisciplinary Innovator. Spreader of Smiles. Staying Awesome, one day at a time.\",\"isFollowing\":null,\"imageId\":\"1*M8tyZeuF0DxuegOCAVlZNw.jpeg\",\"mediumMemberAt\":1546018388000,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:6041b6270883\":{\"id\":\"6041b6270883\",\"__typename\":\"Post\",\"title\":\"MIDI Mashups: Using Machine Learning to Generate Unique Musical Scores\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fmidi-mashups-using-machine-learning-to-generate-unique-musical-scores-6041b6270883\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*N04OvC-wThS6M3rAfJ2VQA.jpeg\"},\"isPublished\":true,\"firstPublishedAt\":1600099573587,\"readingTime\":8.817924528301887,\"statusForCollection\":\"APPROVED\",\"isLocked\":false,\"isShortform\":false,\"visibility\":\"PUBLIC\",\"collection\":{\"__ref\":\"Collection:f5af2b715248\"},\"creator\":{\"__ref\":\"User:d19d33dbfacc\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:0*iJ-vV9uXKugUhLfz\":{\"id\":\"0*iJ-vV9uXKugUhLfz\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"Collection:9de2ecd2d853\":{\"id\":\"9de2ecd2d853\",\"__typename\":\"Collection\",\"name\":\"Teb’s Lab\",\"slug\":\"tebs-lab\",\"domain\":null},\"User:7147db7866ab\":{\"id\":\"7147db7866ab\",\"__typename\":\"User\",\"name\":\"Tyler Elliot Bettilyon\",\"username\":\"TebbaVonMathenstien\",\"bio\":\"A curious human on a quest to watch the world learn. I teach computer programming and write about software’s overlap with society and politics. www.tebs-lab.com\",\"isFollowing\":null,\"imageId\":\"1*ndpsLP54odyB1XXfUrLalA.jpeg\",\"mediumMemberAt\":1525119750000,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:604f6d6c116d\":{\"id\":\"604f6d6c116d\",\"__typename\":\"Post\",\"title\":\"Gradient Descent\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Ftebs-lab\\\\u002Fgradient-descent-604f6d6c116d\",\"previewImage\":{\"__ref\":\"ImageMetadata:0*iJ-vV9uXKugUhLfz\"},\"isPublished\":true,\"firstPublishedAt\":1550109445269,\"readingTime\":12.954088050314466,\"statusForCollection\":\"APPROVED\",\"isLocked\":false,\"isShortform\":false,\"visibility\":\"PUBLIC\",\"collection\":{\"__ref\":\"Collection:9de2ecd2d853\"},\"creator\":{\"__ref\":\"User:7147db7866ab\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"ImageMetadata:1*zzSHIQU2O3jhxLXpmr68EA.png\":{\"id\":\"1*zzSHIQU2O3jhxLXpmr68EA.png\",\"__typename\":\"ImageMetadata\",\"focusPercentX\":null,\"focusPercentY\":null},\"User:a360b2359e97\":{\"id\":\"a360b2359e97\",\"__typename\":\"User\",\"name\":\"Marguerite Siboni\",\"username\":\"margueritesiboni\",\"bio\":\"Mechanical Engineer writing about the things I stumble upon that fascinate me, whether they be topology, pet care or signage. I like data, tv, &sustainability.\",\"isFollowing\":null,\"imageId\":\"2*dJz2yxHQFIvxhwPzt502MQ.jpeg\",\"mediumMemberAt\":1562579894000,\"customDomainState\":null,\"hasSubdomain\":false},\"Post:5f9a4cc94224\":{\"id\":\"5f9a4cc94224\",\"__typename\":\"Post\",\"title\":\"The Non-Coder’s Guide to Image Classification\",\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fa-non-technical-explanation-of-image-classifiers-5f9a4cc94224\",\"previewImage\":{\"__ref\":\"ImageMetadata:1*zzSHIQU2O3jhxLXpmr68EA.png\"},\"isPublished\":true,\"firstPublishedAt\":1567101117535,\"readingTime\":7.000943396226415,\"statusForCollection\":\"APPROVED\",\"isLocked\":true,\"isShortform\":false,\"visibility\":\"LOCKED\",\"collection\":{\"__ref\":\"Collection:f5af2b715248\"},\"creator\":{\"__ref\":\"User:a360b2359e97\"},\"previewContent\":{\"__typename\":\"PreviewContent\",\"isFullContent\":false}},\"Post:5e899c127387\":{\"id\":\"5e899c127387\",\"__typename\":\"Post\",\"canonicalUrl\":\"\",\"collection\":{\"__ref\":\"Collection:f5af2b715248\"},\"content({\\\\\"postMeteringOptions\\\\\":{}})\":{\"__typename\":\"PostContent\",\"isLockedPreviewOnly\":false,\"validatedShareKey\":\"\",\"isCacheableContent\":false,\"bodyModel\":{\"__typename\":\"RichText\",\"paragraphs\":[{\"__ref\":\"Paragraph:c9b2ede9f51e_0\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_1\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_2\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_3\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_4\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_5\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_6\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_7\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_8\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_9\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_10\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_11\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_12\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_13\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_14\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_15\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_16\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_17\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_18\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_19\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_20\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_21\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_22\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_23\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_24\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_25\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_26\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_27\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_28\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_29\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_30\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_31\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_32\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_33\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_34\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_35\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_36\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_37\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_38\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_39\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_40\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_41\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_42\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_43\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_44\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_45\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_46\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_47\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_48\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_49\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_50\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_51\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_52\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_53\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_54\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_55\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_56\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_57\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_58\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_59\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_60\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_61\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_62\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_63\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_64\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_65\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_66\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_67\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_68\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_69\"},{\"__ref\":\"Paragraph:c9b2ede9f51e_70\"}],\"sections\":[{\"__typename\":\"Section\",\"name\":\"b800\",\"startIndex\":0,\"textLayout\":null,\"imageLayout\":null,\"backgroundImage\":null,\"videoLayout\":null,\"backgroundVideo\":null}]}},\"creator\":{\"__ref\":\"User:470b7c52ceb\"},\"customStyleSheet\":null,\"firstPublishedAt\":1601873984562,\"isLocked\":false,\"isPublished\":true,\"isShortform\":false,\"layerCake\":3,\"primaryTopic\":{\"__ref\":\"Topic:1eca0103fff3\"},\"title\":\"Automatic Image Captioning Using Deep Learning\",\"readCreatorPostsCount\":0,\"mediumUrl\":\"https:\\\\u002F\\\\u002Fmedium.com\\\\u002Fswlh\\\\u002Fautomatic-image-captioning-using-deep-learning-5e899c127387\",\"isLimitedState\":false,\"visibility\":\"PUBLIC\",\"license\":\"ALL_RIGHTS_RESERVED\",\"allowResponses\":true,\"newsletterId\":\"\",\"sequence\":null,\"tags\":[{\"__ref\":\"Tag:image-captioning\"},{\"__ref\":\"Tag:machine-learning\"},{\"__ref\":\"Tag:deep-learning\"},{\"__ref\":\"Tag:computer-vision\"},{\"__ref\":\"Tag:naturallanguageprocessing\"}],\"topics\":[{\"__typename\":\"Topic\",\"topicId\":\"1eca0103fff3\",\"name\":\"Machine Learning\"}],\"viewerClapCount\":0,\"showSubscribeToProfilePromo\":false,\"showSubscribeToCollectionNewsletterV3Promo\":false,\"inResponseToPostResult\":null,\"isNewsletter\":false,\"socialTitle\":\"\",\"socialDek\":\"\",\"metaDescription\":\"\",\"latestPublishedAt\":1612676150821,\"readingTime\":6.649056603773585,\"previewContent\":{\"__typename\":\"PreviewContent\",\"subtitle\":\"Overview of Deep Learning:\"},\"previewImage\":{\"__ref\":\"ImageMetadata:0*ENpcH_oTsR4CNlNg.png\"},\"creatorPartnerProgramEnrollmentStatus\":\"PERMISSION_DENIED\",\"clapCount\":58,\"lockedSource\":\"LOCKED_POST_SOURCE_NONE\",\"isSuspended\":false,\"pendingCollection\":null,\"statusForCollection\":\"APPROVED\",\"pinnedAt\":0,\"pinnedByCreatorAt\":0,\"curationEligibleAt\":0,\"responseDistribution\":\"NOT_DISTRIBUTED\",\"shareKey\":null,\"internalLinks({\\\\\"paging\\\\\":{\\\\\"limit\\\\\":8}})\":{\"__typename\":\"InternalLinksConnection\",\"items\":[{\"__ref\":\"Post:5e984ab760be\"},{\"__ref\":\"Post:5eabb6487b9b\"},{\"__ref\":\"Post:5e0deb70cd75\"},{\"__ref\":\"Post:5e1480e6f52a\"},{\"__ref\":\"Post:5df55782b21b\"},{\"__ref\":\"Post:6041b6270883\"},{\"__ref\":\"Post:604f6d6c116d\"},{\"__ref\":\"Post:5f9a4cc94224\"}]},\"collaborators\":[],\"translationSourcePost\":null,\"inResponseToMediaResource\":null,\"isDistributionAlertDismissed\":false,\"audioVersionUrl\":\"\",\"seoTitle\":\"\",\"updatedAt\":1612676160718,\"shortformType\":\"SHORTFORM_TYPE_LINK\",\"structuredData\":\"\",\"seoDescription\":\"\",\"postResponses\":{\"__typename\":\"PostResponses\",\"count\":0},\"latestPublishedVersion\":\"c9b2ede9f51e\",\"isPublishToEmail\":false,\"readingList\":\"READING_LIST_NONE\",\"voterCount\":8,\"recommenders\":[]}}</script><script src=\"https://cdn-client.medium.com/lite/static/js/manifest.0ab54138.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/4575.991e73dc.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/main.31279a23.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/5573.159bf40f.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/instrumentation.4d123e07.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/reporting.ab31910c.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/1752.a348f767.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/4464.c01c0ad8.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8342.6aa0b45e.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/1148.fddd1e85.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/9692.d5b758ae.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/4586.f07c5f16.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/5064.8cb1757e.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/9355.65d243a9.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/2846.53a861ed.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/9990.190d3475.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/7012.09df0a52.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/9972.695972af.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/5127.fe85a910.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8580.17b5364b.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8751.60a43f0e.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/9458.cecea30f.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/7131.899bb049.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8127.a11eec65.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/463.d1112f45.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/1373.008363de.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/587.85cfc09a.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/2514.c67fd96a.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/2558.d91a473a.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/3874.a4d81a48.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/857.d6db2ba9.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8286.08280ee0.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/3414.3ac6c038.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/8831.832d37b6.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/2450.10c6394c.chunk.js\"></script>\\n<script src=\"https://cdn-client.medium.com/lite/static/js/Post.b2e9c91e.chunk.js\"></script><script>window.main();</script></body></html>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text , 'html.parser')\n",
    "results = soup.find_all(['p','h1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [r.text for r in results]\n",
    "ARTICLE = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Automatic Image Captioning Using Deep Learning Overview of Deep Learning: Deep learning and Machine learning are the most progressive technologies in this era. Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans. Day by day there is new research in this field. This field is increasing very fast because now we have sufficient computational power for doing this task. Deep learning is a branch of machine learning that uses neural networks with many layers. In traditional machine learning, the algorithm is given a set of relevant features to analyze. However, in deep learning, the algorithm is given raw data and decides for itself what features are relevant. Deep learning networks will often improve as you increase the amount of data being used to train them. Read More About Simple Explanation of Deep Learning here There Are some very interesting deep learning applications shown below. Source:-https://techvidvan.com/tutorials/deep-learning-applications/ Now We will be going to see one of its applications which is Photo descriptions or image captions generator. Image Captions Generator : Image Caption Generator or Photo Descriptions is one of the Applications of Deep Learning. In Which we have to pass the image to the model and the model does some processing and generating captions or descriptions as per its training. This prediction is sometimes not that much accurate and generates some meaningless sentences. We need very high computational power and a very huge dataset for better results. Now we will see some information about the dataset and the architecture of the neural network of the Image captions generator. Pre-requisites : This project requires good knowledge of Deep learning, Python, working on Jupyter notebooks, Keras library, Numpy, and Natural language Processing Make sure you have installed all the following necessary libraries: Dataset : In this project, we are using the flicker 30k dataset. In which it has 30,000 images with image id and a particular id has 5 captions generated. Here is the link to the dataset so that you can also download that dataset. Flicker_30k:- https://www.kaggle.com/hsankesara/flickr-image-dataset One of the Image in Dataset with ID 1000092795 1000092795.jpg Here are the particular captions for these images which is present in the dataset. The Architecture of Network : 1 .Image Features Detection : For image Detecting, we are using a pre-trained model which is VGG16. VGG16 is already installed in the Keras library.VGG 16 was proposed by Karen Simonyan and Andrew Zisserman of the Visual Geometry Group Lab of Oxford University in 2014 in the paper VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION. This model won the ILSVRC challenge in 2014. Here is the model representation in 3-D and in 2-D. Source:-Very Deep Convolutional Networks for Large-Scale Image Recognition Source:-VGG16 | CNN Model GFG Overview : The input to conv1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left/right, up/down, center). In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3×3 conv. layers. Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2×2 pixel window, with stride 2. Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks. Read More Here 2. Text Generation using LSTM Long Short Term Memory networks — usually just called “LSTMs” — are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997) and were refined and popularized by many people in the following work. They work tremendously well on a large variety of problems and are now widely used. Source:-LSTM Networks Overview : A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. LSTM networks are well-suited to classifying, processing, and making predictions based on time series data since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models, and other sequence learning methods in numerous applications. The advantage of an LSTM cell compared to a common recurrent unit is its cell memory unit. The cell vector has the ability to encapsulate the notion of forgetting part of its previously-stored memory, as well as to add part of the new information. To illustrate this, one has to inspect the equations of the cell and the way it processes sequences under the hood. Now we are combining this model architecture in one model and that is our final model which will generate caption from images. Read Wikipedia:-LSTM Networks Full explained Main Model Architecture: This final model is a combination of CNN and RNN models. To train this model we have to give two inputs two the models. (1) Images (2) Corresponding Captions. For each LSTM layer, we input one word for each LSTM layer, and each LSTM layer predicts the next word, and that how the LSTM model optimizes itself by learning from captions. For Image features, we are getting All image features array from the VGG16 pre-trained model and saved in a file so that we can use this file or features directly to correlate captions and image features with each other. Finally the image features and LSTM last layer we input this both outputs combination into decoder model in which we are adding both image features and captions so that model learns to generate captions from images and for a final layer we generate output or captions which length is the maximum length of dataset captions. The last layer has a size of the length of the vocab. For this model, we are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words. We are using Adam optimizer for optimization of the network or update the weights of the network. Bleu Score : We can generate captions with the n-grams model for that purpose we are using Blue-score for this model. By using BLEU Score we can check which n-gram is best to generate captions for this dataset.BLEU Score lies between 0 and 1. BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of the text to one or more reference translations. Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks. Model Summary : Github: github.com Also, check out my other projects and if you find it useful then don’t forget to give a star. Conclusion : Finally, conclude this project we understand VGG16 model Architecture, Long short term memory Network, how to combine this both model, bleu score, How the LSTM network generates captions, How the VGG16 model we can use for our project, and how to generate captions from images using deep learning. More Blogs On Image Captions: Image Captioning in Python with Keras Image Caption Using Attention Mechanism Automatic Image Captioning With CNN and RNN Thanks for reading! If you enjoyed this article, please hit the clap button as many times as you can. It would mean a lot and encourage me to keep sharing my knowledge. Medium's largest active publication, followed by +768K people. Follow to join our community. 58  58\\xa0claps 58\\xa0claps Written by  Medium's largest active publication, followed by +768K people. Follow to join our community. Written by  Medium's largest active publication, followed by +768K people. Follow to join our community. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium AboutHelpLegal About Help Legal Get the Medium app\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = ARTICLE.replace('.','.<eos>')\n",
    "ARTICLE = ARTICLE.replace('|','|<eos>')\n",
    "ARTICLE = ARTICLE.replace('?','?<eos>')\n",
    "sentences = ARTICLE.split('<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatic Image Captioning Using Deep Learning Overview of Deep Learning: Deep learning and Machine learning are the most progressive technologies in this era.',\n",
       " ' Artificial intelligence is now compared with the human mind and in some field AI doing a great job than humans.',\n",
       " ' Day by day there is new research in this field.',\n",
       " ' This field is increasing very fast because now we have sufficient computational power for doing this task.',\n",
       " ' Deep learning is a branch of machine learning that uses neural networks with many layers.',\n",
       " ' In traditional machine learning, the algorithm is given a set of relevant features to analyze.',\n",
       " ' However, in deep learning, the algorithm is given raw data and decides for itself what features are relevant.',\n",
       " ' Deep learning networks will often improve as you increase the amount of data being used to train them.',\n",
       " ' Read More About Simple Explanation of Deep Learning here There Are some very interesting deep learning applications shown below.',\n",
       " ' Source:-https://techvidvan.',\n",
       " 'com/tutorials/deep-learning-applications/ Now We will be going to see one of its applications which is Photo descriptions or image captions generator.',\n",
       " ' Image Captions Generator : Image Caption Generator or Photo Descriptions is one of the Applications of Deep Learning.',\n",
       " ' In Which we have to pass the image to the model and the model does some processing and generating captions or descriptions as per its training.',\n",
       " ' This prediction is sometimes not that much accurate and generates some meaningless sentences.',\n",
       " ' We need very high computational power and a very huge dataset for better results.',\n",
       " ' Now we will see some information about the dataset and the architecture of the neural network of the Image captions generator.',\n",
       " ' Pre-requisites : This project requires good knowledge of Deep learning, Python, working on Jupyter notebooks, Keras library, Numpy, and Natural language Processing Make sure you have installed all the following necessary libraries: Dataset : In this project, we are using the flicker 30k dataset.',\n",
       " ' In which it has 30,000 images with image id and a particular id has 5 captions generated.',\n",
       " ' Here is the link to the dataset so that you can also download that dataset.',\n",
       " ' Flicker_30k:- https://www.',\n",
       " 'kaggle.',\n",
       " 'com/hsankesara/flickr-image-dataset One of the Image in Dataset with ID 1000092795 1000092795.',\n",
       " 'jpg Here are the particular captions for these images which is present in the dataset.',\n",
       " ' The Architecture of Network : 1 .',\n",
       " 'Image Features Detection : For image Detecting, we are using a pre-trained model which is VGG16.',\n",
       " ' VGG16 is already installed in the Keras library.',\n",
       " 'VGG 16 was proposed by Karen Simonyan and Andrew Zisserman of the Visual Geometry Group Lab of Oxford University in 2014 in the paper VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.',\n",
       " ' This model won the ILSVRC challenge in 2014.',\n",
       " ' Here is the model representation in 3-D and in 2-D.',\n",
       " ' Source:-Very Deep Convolutional Networks for Large-Scale Image Recognition Source:-VGG16 |',\n",
       " ' CNN Model GFG Overview : The input to conv1 layer is of fixed size 224 x 224 RGB image.',\n",
       " ' The image is passed through a stack of convolutional (conv.',\n",
       " ') layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left/right, up/down, center).',\n",
       " ' In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity).',\n",
       " ' The convolution stride is fixed to 1 pixel; the spatial padding of conv.',\n",
       " ' layer input is such that the spatial resolution is preserved after convolution, i.',\n",
       " 'e.',\n",
       " ' the padding is 1-pixel for 3×3 conv.',\n",
       " ' layers.',\n",
       " ' Spatial pooling is carried out by five max-pooling layers, which follow some of the conv.',\n",
       " ' layers (not all the conv.',\n",
       " ' layers are followed by max-pooling).',\n",
       " ' Max-pooling is performed over a 2×2 pixel window, with stride 2.',\n",
       " ' Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class).',\n",
       " ' The final layer is the soft-max layer.',\n",
       " ' The configuration of the fully connected layers is the same in all networks.',\n",
       " ' Read More Here 2.',\n",
       " ' Text Generation using LSTM Long Short Term Memory networks — usually just called “LSTMs” — are a special kind of RNN, capable of learning long-term dependencies.',\n",
       " ' They were introduced by Hochreiter & Schmidhuber (1997) and were refined and popularized by many people in the following work.',\n",
       " ' They work tremendously well on a large variety of problems and are now widely used.',\n",
       " ' Source:-LSTM Networks Overview : A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate.',\n",
       " ' The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.',\n",
       " ' LSTM networks are well-suited to classifying, processing, and making predictions based on time series data since there can be lags of unknown duration between important events in a time series.',\n",
       " ' LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs.',\n",
       " ' Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models, and other sequence learning methods in numerous applications.',\n",
       " ' The advantage of an LSTM cell compared to a common recurrent unit is its cell memory unit.',\n",
       " ' The cell vector has the ability to encapsulate the notion of forgetting part of its previously-stored memory, as well as to add part of the new information.',\n",
       " ' To illustrate this, one has to inspect the equations of the cell and the way it processes sequences under the hood.',\n",
       " ' Now we are combining this model architecture in one model and that is our final model which will generate caption from images.',\n",
       " ' Read Wikipedia:-LSTM Networks Full explained Main Model Architecture: This final model is a combination of CNN and RNN models.',\n",
       " ' To train this model we have to give two inputs two the models.',\n",
       " ' (1) Images (2) Corresponding Captions.',\n",
       " ' For each LSTM layer, we input one word for each LSTM layer, and each LSTM layer predicts the next word, and that how the LSTM model optimizes itself by learning from captions.',\n",
       " ' For Image features, we are getting All image features array from the VGG16 pre-trained model and saved in a file so that we can use this file or features directly to correlate captions and image features with each other.',\n",
       " ' Finally the image features and LSTM last layer we input this both outputs combination into decoder model in which we are adding both image features and captions so that model learns to generate captions from images and for a final layer we generate output or captions which length is the maximum length of dataset captions.',\n",
       " ' The last layer has a size of the length of the vocab.',\n",
       " ' For this model, we are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words.',\n",
       " ' We are using Adam optimizer for optimization of the network or update the weights of the network.',\n",
       " ' Bleu Score : We can generate captions with the n-grams model for that purpose we are using Blue-score for this model.',\n",
       " ' By using BLEU Score we can check which n-gram is best to generate captions for this dataset.',\n",
       " 'BLEU Score lies between 0 and 1.',\n",
       " ' BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of the text to one or more reference translations.',\n",
       " ' Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks.',\n",
       " ' Model Summary : Github: github.',\n",
       " 'com Also, check out my other projects and if you find it useful then don’t forget to give a star.',\n",
       " ' Conclusion : Finally, conclude this project we understand VGG16 model Architecture, Long short term memory Network, how to combine this both model, bleu score, How the LSTM network generates captions, How the VGG16 model we can use for our project, and how to generate captions from images using deep learning.',\n",
       " ' More Blogs On Image Captions: Image Captioning in Python with Keras Image Caption Using Attention Mechanism Automatic Image Captioning With CNN and RNN Thanks for reading! If you enjoyed this article, please hit the clap button as many times as you can.',\n",
       " ' It would mean a lot and encourage me to keep sharing my knowledge.',\n",
       " \" Medium's largest active publication, followed by +768K people.\",\n",
       " ' Follow to join our community.',\n",
       " \" 58  58\\xa0claps 58\\xa0claps Written by  Medium's largest active publication, followed by +768K people.\",\n",
       " ' Follow to join our community.',\n",
       " \" Written by  Medium's largest active publication, followed by +768K people.\",\n",
       " ' Follow to join our community.',\n",
       " ' Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.',\n",
       " ' Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface.',\n",
       " ' Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox.',\n",
       " ' Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home.',\n",
       " ' It’s easy and free to post your thinking on any topic.',\n",
       " ' Write on Medium AboutHelpLegal About Help Legal Get the Medium app']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_chunk = 500\n",
    "current_chunk = 0\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    if len(chunks) == current_chunk + 1:\n",
    "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
    "            chunks[current_chunk].extend(sentence.split(' '))\n",
    "        else:\n",
    "            current_chunk += 1\n",
    "            chunks.append(sentence.split(' '))\n",
    "    else:\n",
    "        print(current_chunk)\n",
    "        chunks.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '58',\n",
       " '',\n",
       " '58\\xa0claps',\n",
       " '58\\xa0claps',\n",
       " 'Written',\n",
       " 'by',\n",
       " '',\n",
       " \"Medium's\",\n",
       " 'largest',\n",
       " 'active',\n",
       " 'publication,',\n",
       " 'followed',\n",
       " 'by',\n",
       " '+768K',\n",
       " 'people.',\n",
       " '',\n",
       " 'Follow',\n",
       " 'to',\n",
       " 'join',\n",
       " 'our',\n",
       " 'community.',\n",
       " '',\n",
       " 'Written',\n",
       " 'by',\n",
       " '',\n",
       " \"Medium's\",\n",
       " 'largest',\n",
       " 'active',\n",
       " 'publication,',\n",
       " 'followed',\n",
       " 'by',\n",
       " '+768K',\n",
       " 'people.',\n",
       " '',\n",
       " 'Follow',\n",
       " 'to',\n",
       " 'join',\n",
       " 'our',\n",
       " 'community.',\n",
       " '',\n",
       " 'Medium',\n",
       " 'is',\n",
       " 'an',\n",
       " 'open',\n",
       " 'platform',\n",
       " 'where',\n",
       " '170',\n",
       " 'million',\n",
       " 'readers',\n",
       " 'come',\n",
       " 'to',\n",
       " 'find',\n",
       " 'insightful',\n",
       " 'and',\n",
       " 'dynamic',\n",
       " 'thinking.',\n",
       " '',\n",
       " 'Here,',\n",
       " 'expert',\n",
       " 'and',\n",
       " 'undiscovered',\n",
       " 'voices',\n",
       " 'alike',\n",
       " 'dive',\n",
       " 'into',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'of',\n",
       " 'any',\n",
       " 'topic',\n",
       " 'and',\n",
       " 'bring',\n",
       " 'new',\n",
       " 'ideas',\n",
       " 'to',\n",
       " 'the',\n",
       " 'surface.',\n",
       " '',\n",
       " 'Learn',\n",
       " 'more',\n",
       " 'Follow',\n",
       " 'the',\n",
       " 'writers,',\n",
       " 'publications,',\n",
       " 'and',\n",
       " 'topics',\n",
       " 'that',\n",
       " 'matter',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'and',\n",
       " 'you’ll',\n",
       " 'see',\n",
       " 'them',\n",
       " 'on',\n",
       " 'your',\n",
       " 'homepage',\n",
       " 'and',\n",
       " 'in',\n",
       " 'your',\n",
       " 'inbox.',\n",
       " '',\n",
       " 'Explore',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'story',\n",
       " 'to',\n",
       " 'tell,',\n",
       " 'knowledge',\n",
       " 'to',\n",
       " 'share,',\n",
       " 'or',\n",
       " 'a',\n",
       " 'perspective',\n",
       " 'to',\n",
       " 'offer',\n",
       " '—',\n",
       " 'welcome',\n",
       " 'home.',\n",
       " '',\n",
       " 'It’s',\n",
       " 'easy',\n",
       " 'and',\n",
       " 'free',\n",
       " 'to',\n",
       " 'post',\n",
       " 'your',\n",
       " 'thinking',\n",
       " 'on',\n",
       " 'any',\n",
       " 'topic.',\n",
       " '',\n",
       " 'Write',\n",
       " 'on',\n",
       " 'Medium',\n",
       " 'AboutHelpLegal',\n",
       " 'About',\n",
       " 'Help',\n",
       " 'Legal',\n",
       " 'Get',\n",
       " 'the',\n",
       " 'Medium',\n",
       " 'app']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_id in range(len(chunks)):\n",
    "    chunks[chunk_id] = ' '.join(chunks[chunk_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 58  58\\xa0claps 58\\xa0claps Written by  Medium's largest active publication, followed by +768K people.  Follow to join our community.  Written by  Medium's largest active publication, followed by +768K people.  Follow to join our community.  Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.  Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface.  Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox.  Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home.  It’s easy and free to post your thinking on any topic.  Write on Medium AboutHelpLegal About Help Legal Get the Medium app\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchunks = created above \\nmax_length = max no. of words in summary\\nmin_length = min no. of words in summary\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = summarizer(chunks , max_length = 120 , min_length = 30 , do_sample = False)\n",
    "'''\n",
    "chunks = created above \n",
    "max_length = max no. of words in summary\n",
    "min_length = min no. of words in summary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Deep learning is a branch of machine learning that uses neural networks with many layers . We will be going to see one of its applications which is Photo descriptions or image captions generator . We are using the flicker 30k dataset which has 30,000 images with image id and a particular id has 5 captions .'},\n",
       " {'summary_text': ' Long Short Term Memory networks are a special kind of RNN, capable of learning long-term dependencies . They work tremendously well on a large variety of problems and are now widely used . LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs .'},\n",
       " {'summary_text': ' VGG16 model Architecture, Long short term memory Network, how to combine this both model and how the LSTM network generates captions . We are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words . We can generate captions with the n-grams model for that purpose we are using Blue-score for this model .'},\n",
       " {'summary_text': ' Medium is an open platform where 170 million readers come to find insightful and dynamic thinking . Here, expert and undiscovered voices dive into the heart of any topic and bring new ideas to the surface .'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Deep learning is a branch of machine learning that uses neural networks with many layers . We will be going to see one of its applications which is Photo descriptions or image captions generator . We are using the flicker 30k dataset which has 30,000 images with image id and a particular id has 5 captions .  Long Short Term Memory networks are a special kind of RNN, capable of learning long-term dependencies . They work tremendously well on a large variety of problems and are now widely used . LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs .  VGG16 model Architecture, Long short term memory Network, how to combine this both model and how the LSTM network generates captions . We are using ‘categorical cross-entropy ’ because in the last layer we have to predict each word probability and then we are only using high probability words . We can generate captions with the n-grams model for that purpose we are using Blue-score for this model .  Medium is an open platform where 170 million readers come to find insightful and dynamic thinking . Here, expert and undiscovered voices dive into the heart of any topic and bring new ideas to the surface .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blogsummary2.txt','w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
